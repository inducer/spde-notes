<TeXmacs|1.0.6>

<style|<tuple|article|number-long-article|spdestyle>>

<\body>
  <doc-data|<doc-title|Stochastic PDEs>|<doc-author-data|<author-name|Boris
  Rozovsky>>>

  <\table-of-contents|toc>
    <vspace*|1fn><with|font-series|bold|math-font-series|bold|Table of
    contents> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-1><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|1<space|2spc>Basic
    Facts from Stochastic Processes> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-2><vspace|0.5fn>

    <with|par-left|1.5fn|1.1<space|2spc>Lebesgue Integral
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-3>>

    <with|par-left|1.5fn|1.2<space|2spc>Conditional Expectation
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-4>>

    <with|par-left|1.5fn|1.3<space|2spc>Stochastic Processes
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-5>>

    <with|par-left|1.5fn|1.4<space|2spc>Brownian Motion (Wiener Processes)
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-6>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|2<space|2spc>The
    Itô Integral and Formula> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-7><vspace|0.5fn>

    <with|par-left|1.5fn|2.1<space|2spc>The Itô Construction
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-8>>

    <with|par-left|1.5fn|2.2<space|2spc>Itô's Formula
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-9>>

    <with|par-left|3fn|2.2.1<space|2spc>Deriving from the Chain Rule
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-10>>

    <with|par-left|3fn|2.2.2<space|2spc>SODEs
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-11>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|3<space|2spc>Some
    SPDEs> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-12><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|4<space|2spc>PDE/Sobolev
    Recap> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-13><vspace|0.5fn>

    <with|par-left|1.5fn|4.1<space|2spc>Sobolev Spaces
    <with|mode|math|H<rsub|2><rsup|\<gamma\>>>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-14>>

    <with|par-left|1.5fn|4.2<space|2spc>SPDEs in Sobolev Spaces
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-15>>

    <with|par-left|3fn|4.2.1<space|2spc>Classical Theory
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-16>>

    <with|par-left|3fn|4.2.2<space|2spc>Stochastic Theory
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-17>>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|5<space|2spc>Nonlinear
    Filtering (``Hidden Markov Models'')>
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-18><vspace|0.5fn>

    <vspace*|1fn><with|font-series|bold|math-font-series|bold|6<space|2spc>Solutions
    of PDEs and SPDEs> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-19><vspace|0.5fn>

    <with|par-left|1.5fn|6.1<space|2spc>Classical Solutions
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-20>>

    <with|par-left|1.5fn|6.2<space|2spc>Generalized Solutions
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-21>>

    <with|par-left|1.5fn|6.3<space|2spc>Mild Solutions
    <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-22>>

    <with|par-left|1.5fn|6.4<space|2spc>Generalization of the notion of a
    ``solution'' in SDE <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
    <no-break><pageref|auto-23>>
  </table-of-contents>

  Send corrections to <with|font-family|tt|kloeckner@dam.brown.edu>.

  \;

  Example: Heat Equation. Suppose <with|mode|math|\<omega\>\<in\>\<Omega\>>
  is part of a probability space. Then chance can come in at any or all of
  these points:

  <\eqnarray*>
    <tformat|<table|<row|<cell|<frac|\<partial\>u(t,x)|\<partial\>t>>|<cell|=>|<cell|a(x,<with|color|orange|\<omega\>>)<frac|\<partial\><rsup|2>|\<partial\>x<rsup|2>>u(t,x)+f(t,x,<with|color|orange|\<omega\>>)<space|1em>x\<in\>(a,b)>>|<row|<cell|u(0,x)>|<cell|=>|<cell|\<varphi\>(x,<with|color|orange|\<omega\>>)>>|<row|<cell|u(t,a)>|<cell|=>|<cell|\<psi\><rsub|1>(t,<with|color|orange|\<omega\>>)>>|<row|<cell|u(t,b)>|<cell|=>|<cell|\<psi\><rsub|2>(t,<with|color|orange|\<omega\>>)>>>>
  </eqnarray*>

  <section|Basic Facts from Stochastic Processes>

  <tabular|<tformat|<cwith|1|1|1|-1|cell-bborder|0.5pt>|<cwith|1|-1|2|2|cell-lborder|0.5pt>|<table|<row|<cell|Probability
  Theory>|<cell|Measure Theory>>|<row|<cell|<with|mode|math|\<omega\>> --
  elementary random event (outcomes)>|<cell|>>|<row|<cell|<with|mode|math|\<Omega\>=<big|cup>\<omega\>>
  -- probability space/space of outcomes>|<cell|<with|mode|math|\<Omega\>> --
  set>>|<row|<cell|Random events <with|mode|math|\<leftrightarrow\>> subsets
  of <with|mode|math|\<Omega\>\<supset\>A>>|<cell|Algebra
  <with|mode|math|\<cal-A\>\<subset\>\<cal-P\>(\<Omega\>)> closed w.r.t.
  <with|mode|math|\<cap\>>/<with|mode|math|\<cup\>>/<with|mode|math|<wide|\<cdot\>|\<bar\>>>.>>|<row|<cell|Operations
  on events: <with|mode|math|\<cup\>>, <with|mode|math|\<cap\>>,
  <with|mode|math|<wide|A|\<bar\>>=\<Omega\>\<setminus\>A>.>|<cell|>>|<row|<cell|<with|mode|math|\<varnothing\>\<assign\>\<Omega\>\<setminus\>\<Omega\>>>|<cell|>>|<row|<cell|If
  <with|mode|math|A> and <with|mode|math|B> are random events, then
  <with|mode|math|A\<cup\>B>, <with|mode|math|A\<cap\>B>,
  <with|mode|math|<wide|A|\<bar\>>> are r.e.>|<cell|>>|<row|<cell|Elementary
  properties of probability:>|<cell|Measures (see
  below)>>|<row|<cell|<with|mode|math|P(A)\<in\>[0,1]>,
  <with|mode|math|P(\<Omega\>)=1>, additive for disjoint events.>|<cell|>>>>>

  <\definition>
    A function <with|mode|math|\<mu\>(A)> on the sets of an algebra
    <with|mode|math|\<cal-A\>> is called a <em|measure> if

    <\enumerate-alpha>
      <item>the values of <with|mode|math|\<mu\>> are non-negative and real,

      <item><with|mode|math|\<mu\>> is an additive function for any finite
      expression--explicitly, if <with|mode|math|A=<big|cup><rsub|i>A<rsub|i>>
      and <with|mode|math|A<rsub|i>\<cap\>A<rsub|j>=\<varnothing\>> iff
      <with|mode|math|i\<neq\>j>, then

      <\equation*>
        \<mu\>(A)=<big|sum><rsub|i=1><rsup|n>\<mu\>(A<rsub|i>).
      </equation*>
    </enumerate-alpha>
  </definition>

  <\definition>
    A system <with|mode|math|\<cal-F\>\<subset\>\<cal-P\>(\<Omega\>)> is
    called a <em|<with|mode|math|\<sigma\>>-algebra> if it is an algebra and,
    in addition, if <with|mode|math|(A<rsub|i>)<rsub|i=1,2,\<ldots\>>>, then
    also <with|mode|math|<big|cup><rsub|i>A<rsub|i>\<in\>\<cal-F\>>.
  </definition>

  It is an easy consequence that <with|mode|math|<big|cap><rsub|i>A<rsub|i>\<in\>\<cal-F\>>.

  <\definition>
    A measure is called <em|<with|mode|math|\<sigma\>>-additive> if

    <\equation*>
      \<mu\><left|(><big|cup><rsub|i=1><rsup|\<infty\>>A<rsub|i><right|)>=<big|sum><rsub|i=1><rsup|\<infty\>>\<mu\>(A<rsub|i>)
    </equation*>

    if the <with|mode|math|A<rsub|i>> are mutually disjoint.
  </definition>

  The above together form <em|Kolmogorov's Axioms of Probability:> A tuple
  <with|mode|math|(\<Omega\>,\<cal-F\>,P)> is called a <em|probability space>
  (<with|mode|math|\<Omega\>> a set, <with|mode|math|\<cal-F\>> a
  <with|mode|math|\<sigma\>>-algebra, <with|mode|math|P> a probability
  measure).

  <\lemma>
    Let <with|mode|math|\<varepsilon\>> be a set of events. Then there is a
    smallest <with|mode|math|\<sigma\>>-algebra <with|mode|math|\<cal-F\>>
    such that <with|mode|math|\<varepsilon\>\<subset\>\<cal-F\>>.
  </lemma>

  <\definition>
    A function <with|mode|math|X:\<Omega\>\<rightarrow\>\<bbb-R\><rsup|n>> is
    called a <em|random variable> if it is
    <with|mode|math|\<cal-F\>>-measurable, i.e. for arbitrary
    <with|mode|math|A> belonging to the Borel-<with|mode|math|\<sigma\>>-algebra
    <with|mode|math|\<cal-B\>(\<bbb-R\><rsup|n>)>, the set
    <with|mode|math|X<rsup|-1>(A)\<in\>\<cal-F\>>.
  </definition>

  <\definition>
    <em|Completion of <with|mode|math|\<cal-F\>> with respect to
    <with|mode|math|P>>: For simplicity, <with|mode|math|\<Omega\>=(0,1)>.
    <with|mode|math|P> is the <em|Lebesgue measure>,
    <with|mode|math|\<cal-F\>> the Borel-<with|mode|math|\<sigma\>>-algebra
    <with|mode|math|\<cal-B\>(0,1)> on <with|mode|math|\<Omega\>=(0,1)>.
    <with|mode|math|\<cal-F\>> is called complete if it contains all subsets
    <with|mode|math|B> of <with|mode|math|\<Omega\>> with the property:

    <\quote-env>
      There are subsets <with|mode|math|B<rsup|->> and
      <with|mode|math|B<rsup|+>> from <with|mode|math|\<cal-B\>(0,1)> such
      that <with|mode|math|B<rsup|->\<subset\>B\<subset\>B<rsup|+>> and
      <with|mode|math|P(B<rsup|+>\<setminus\>B<rsup|->)=0>.
    </quote-env>

    This process maps <with|mode|math|(\<Omega\>,\<cal-F\>,P)> to
    <with|mode|math|(\<Omega\>,<wide|\<cal-F\>|\<bar\>><rsup|P>,P)>, where
    <with|mode|math|<wide|\<cal-F\>|\<bar\>><rsup|P>> is the <em|completion>
    of <with|mode|math|\<cal-F\>> w.r.t. <with|mode|math|P>.
  </definition>

  Now suppose <with|mode|math|X> is a random variable in
  <with|mode|math|(\<Omega\>,\<cal-F\>,P)> in
  <with|mode|math|\<bbb-R\><rsup|n>>. <with|mode|math|X<rsup|-1>(\<cal-B\>(\<bbb-R\><rsup|n>))\<assign\>{X<rsup|-1>(A):A\<in\>\<cal-B\>(\<bbb-R\><rsup|n>)}={\<Gamma\>:X(\<Gamma\>)\<in\>\<cal-B\>(\<bbb-R\><rsup|n>)}>.
  <with|mode|math|\<cal-H\><rsub|X>> is called the
  <with|mode|math|\<sigma\>>-algebra generated by <with|mode|math|X>.

  One reason to use this definition of a random variable is this:

  <\lemma>
    <dueto|Doob-Dynkin>If <with|mode|math|\<cal-F\>> is generated by a random
    variable <with|mode|math|Y>, then there exists a Borel function
    <with|mode|math|g> such that <with|mode|math|X=g(Y)>.
  </lemma>

  <subsection|Lebesgue Integral>

  <\definition>
    <with|mode|math|X> on <with|mode|math|(\<Omega\>,\<cal-F\>,P)> is called
    simple if it is <with|mode|math|\<cal-F\>>-measurable and takes a finite
    number of values: <with|mode|math|x<rsub|1>,x<rsub|2>,\<ldots\>,x<rsub|n>>.

    <with|mode|math|\<Omega\><rsub|i>={\<omega\>:X(\<omega\>)=x<rsub|i>}=X<rsup|-1>(x<rsub|i>)>.
    Then the Lebesuge integral is

    <\equation*>
      <big|int><rsub|\<Omega\>>X\<mathd\>P=<big|sum><rsub|i=1><rsup|n>x<rsub|i>P(\<Omega\><rsub|i>).
    </equation*>
  </definition>

  <\definition>
    An arbitrary measurable function <with|mode|math|X> on
    <with|mode|math|(\<Omega\>,\<cal-F\>,P)> is called
    <with|mode|math|P>-integrable if there exists a sequence of such simple
    functions <with|mode|math|X<rsub|n>> so that
    <with|mode|math|X<rsub|n>\<rightarrow\>X> a.s. and

    <\equation*>
      lim<rsub|n,m\<rightarrow\>\<infty\>><big|int><rsub|\<Omega\>>\|X<rsub|n>-X<rsub|m>\|\<mathd\>P=0.
    </equation*>
  </definition>

  <\lemma>
    If <with|mode|math|X> is <with|mode|math|P>-integrable, then

    <\enumerate-numeric>
      <item>There exists a <em|finite> limit

      <\equation*>
        <big|int><rsub|\<Omega\>>X\<mathd\>P=lim<rsub|n\<rightarrow\>\<infty\>><big|int><rsub|\<Omega\>>X<rsub|n>\<mathd\>P.
      </equation*>

      <item>This limit does not depend on the choice of the approximating
      system.
    </enumerate-numeric>
  </lemma>

  If <with|mode|math|X> is a random variable
  <with|mode|math|X:\<Omega\>\<rightarrow\>\<bbb-R\><rsup|n>>. Let
  <with|mode|math|\<cal-B\>> be Borel's <with|mode|math|\<sigma\>>-algebra on
  <with|mode|math|\<bbb-R\><rsup|n>>. Then

  <\equation*>
    \<mu\><rsub|X>(<wide*|A|\<wide-underbrace\>><rsub|\<in\>\<cal-B\>>)=P(X<rsup|-1>(A))=P(\<omega\>:X(\<omega\>)\<in\>A)
  </equation*>

  is called the <em|distribution function> of <with|mode|math|X>.

  <\theorem>
    <\equation*>
      <big|int><rsub|\<Omega\>>f(X)\<mathd\>P=<big|int><rsub|\<bbb-R\><rsup|n>>f(x)\<mu\><rsub|X>(\<mathd\>x).
    </equation*>

    Thus

    <\equation*>
      E[X]=<big|int><rsub|\<bbb-R\><rsup|n>>X\<mu\><rsub|X>(\<mathd\>X).
    </equation*>
  </theorem>

  <\example>
    Let <with|mode|math|X> have values <with|mode|math|x<rsub|1>,\<ldots\>,x<rsub|n>>.
    <with|mode|math|\<Omega\><rsub|i>=X<rsup|-1>(x<rsub|i>).>
    <with|mode|math|\<mu\><rsub|X>(x<rsub|i>)=P(\<Omega\><rsub|i>)>. Then

    <\equation*>
      E[X]=<big|sum>x<rsub|i>\<mu\><rsub|X>(x<rsub|i>)=<big|sum>x<rsub|i>P(\<Omega\><rsub|i>).
    </equation*>
  </example>

  <subsection|Conditional Expectation>

  <with|mode|math|\<xi\>> and <with|mode|math|\<eta\>> are are random
  variables with a joint density <with|mode|math|p(x,y)>.

  <em|Motivation:>

  <\equation*>
    E[\<xi\>\|\<eta\>=y]=<big|int>x*p(x\|y)\<mathd\>x.
  </equation*>

  <\equation*>
    P(A\|B)=<frac|P(A\<cap\>B)|P(B)>.
  </equation*>

  Now suppose <with|mode|math|X> is a <with|mode|math|P>-integrable random
  variable <with|mode|math|(\<Omega\>,\<cal-F\>,P)>. <with|mode|math|G> is a
  <with|mode|math|\<sigma\>>-algebra on <with|mode|math|\<Omega\>>,
  <with|mode|math|\<cal-G\>\<subset\>\<cal-F\>>.

  <\definition>
    Let <with|mode|math|\<eta\>> be <with|mode|math|\<cal-F\>>-measurable
    random variable. If there exists a <with|mode|math|P>-integrable
    <with|mode|math|\<cal-G\>>-measurable function <with|mode|math|\<xi\>>
    such that for any bounded <with|mode|math|\<cal-G\>>-measurable function
    <with|mode|math|\<varphi\>>

    <\equation*>
      E(\<xi\>\<varphi\>)=E(\<eta\>\<varphi\>),
    </equation*>

    the <with|mode|math|\<xi\>> will be called <em|conditional expectation>
    of <with|mode|math|\<eta\>> and denoted
    <with|mode|math|E[\<eta\>\|\<cal-G\>]>.
  </definition>

  Properties of conditional expectation:

  <\enumerate-numeric>
    <item>If <with|mode|math|\<eta\>> is <with|mode|math|\<cal-G\>>-measurable,
    then <with|mode|math|E[\<eta\>\|\<cal-G\>]=\<eta\>>.

    <\proof>
      (1) By assumption, <with|mode|math|\<eta\>> is
      <with|mode|math|\<cal-G\>>-measurable. (2) Let
      <with|mode|math|\<varphi\>> be an arbitrary
      <with|mode|math|\<cal-G\>>-measurable function. Then

      <\equation*>
        E(\<eta\>\<varphi\>)=E(E(\<eta\>\|\<cal-G\>)\<varphi\>)=E(\<eta\>\<varphi\>).
      </equation*>
    </proof>

    <item><with|color|orange|HW:> Prove that the conditional expectation is
    unique.

    <item>If <with|mode|math|f> is bounded,
    <with|mode|math|\<cal-G\>>-measurable, then

    <\equation*>
      E[f(\<omega\>)X\|\<cal-G\>](\<omega\>)=f*(\<omega\>)E[X\|\<cal-G\>]<space|1em>(<with|mode|text|a.s.>)
    </equation*>

    <item>Let <with|mode|math|g(\<omega\>,X)> be an
    <with|mode|math|\<cal-F\>>-measurable function. Then

    <\equation*>
      E[g(\<omega\>,X)\|\<sigma\>(X)]=E[g(\<omega\>,c)\|\<sigma\>(X)]\|<rsub|c=X>.
    </equation*>

    <item>Let <with|mode|math|\<cal-G\><rsub|1>\<subset\>\<cal-G\>> be
    <with|mode|math|\<sigma\>>-algebras. Then

    <\equation*>
      E[E[X\|\<cal-G\>]\|\<cal-G\><rsub|1>]=E[X\|\<cal-G\><rsub|1>].
    </equation*>

    This property can be memorized as ``Small eats big''.
  </enumerate-numeric>

  <\example>
    <with|mode|math|\<Omega\>=<big|cup><rsub|n>\<Omega\><rsub|n>>,
    <with|mode|math|\<Omega\><rsub|i>\<cap\>\<Omega\><rsub|j>=\<varnothing\>>.
    Let <with|mode|math|\<cal-E\>={\<Omega\><rsub|1>,\<Omega\><rsub|2>,\<ldots\>}>.
    Then <with|mode|math|\<sigma\>(\<cal-E\>)={\<Omega\><rsub|i<rsub|1>>\<cup\>\<Omega\><rsub|i<rsub|2>>\<cup\>\<ldots\>}>.
    <with|mode|math|\<Omega\><rsub|0>=<with|color|red|\<Omega\>\<setminus\>\<Omega\>>?>.
    Let <with|mode|math|\<xi\>> be a random variable

    <\equation>
      <label|eq:ce-example-exp>E[\<xi\>\|\<sigma\>(\<cal-E\>)]=<big|sum><rsub|i><frac|E[\<xi\>\<b-1\><rsub|\<Omega\><rsub|i>>]|P(\<Omega\><rsub|i>)>\<b-1\><rsub|\<Omega\><rsub|i>>.
    </equation>

    Proof of (<reference|eq:ce-example-exp>):

    <\enumerate-alpha>
      <item>The right-hand side is a function of indicators of
      <with|mode|math|\<Omega\><rsub|i>><with|mode|math|\<Rightarrow\>>it is
      <with|mode|math|\<sigma\>(\<cal-E\>)>-measurable.

      <item><with|mode|math|E<left|[>E[\<xi\>\|\<sigma\>(\<cal-E\>)]g]=E\<xi\>g>
      for all <with|mode|math|g> which are
      <with|mode|math|\<sigma\>(\<cal-E\>)>-measurable.

      Suppose <with|mode|math|g=1<rsub|\<Omega\><rsub|k>>>. Then

      <\equation*>
        E[rhs*\<b-1\><rsub|\<Omega\><rsub|k>>]=E<left|[><frac|E[\<xi\>\<b-1\><rsub|\<Omega\>k>]|P(\<Omega\><rsub|k>)>\<b-1\><rsub|\<Omega\><rsub|k>><right|]>=<frac|E[\<xi\>\<b-1\><rsub|\<Omega\><rsub|k>>]|<neg|P(\<Omega\><rsub|k>)>><neg|P(\<Omega\><rsub|k>)>=E(\<xi\>\<b-1\><rsub|\<Omega\><rsub|k>>).
      </equation*>

      rhs: <with|mode|math|E(\<xi\>\<b-1\><rsub|\<Omega\><rsub|k>>)>. What is
      a <with|mode|math|\<sigma\>(\<cal-E\>)>-measurable function? Answer: It
      is a function of the form

      <\equation*>
        \<xi\>=<big|sum><rsub|i>y<rsub|i>\<b-1\><rsub|\<Omega\><rsub|i>>.
      </equation*>

      <with|color|red|What?>
    </enumerate-alpha>
  </example>

  <subsection|Stochastic Processes>

  Assume that for all <with|mode|math|t>, we are given a random variable
  <with|mode|math|X<rsub|t>=X<rsub|t>(\<omega\>)\<in\>\<bbb-R\><rsup|n>>.
  <with|mode|math|t> could be from <with|mode|math|{0,1,2,3,\<ldots\>}> or
  from <with|mode|math|(a,b)>, it does not matter. In the former case,
  <with|mode|math|X<rsub|t>> is called a sequence of r.v. or a discrete time
  stochastic process. In the latter, it is called a continuous time
  stochastic process. If <with|mode|math|t\<in\>\<bbb-R\><rsup|2>>, then
  <with|mode|math|X<rsub|t>> is a two-parameter random field.

  <em|Motivation:> If <with|mode|math|X> is a random variable,
  <with|mode|math|\<mu\><rsub|X>(A)=P(\<omega\>:X(\<omega\>)\<in\>A>.

  <\definition>
    The (finite-dimensional) distribution of the stochastic process
    <with|mode|math|(X<rsub|t>)<rsub|t\<in\>T>> are the measures defined on
    <with|mode|math|\<bbb-R\><rsup|n*k>=\<bbb-R\><rsup|n>\<otimes\>\<cdots\>\<bbb-R\><rsup|n>>
    given by

    <\equation*>
      \<mu\><rsub|t<rsub|1>,\<ldots\>,t<rsub|k>>(F<rsub|1>\<otimes\>F<rsub|2>\<otimes\>\<cdots\>\<otimes\>F<rsub|k>)=P(\<omega\>:X<rsub|t<rsub|1>>\<in\>F<rsub|1>,\<ldots\>,X<rsub|t<rsub|k>>\<in\>F<rsub|k>),
    </equation*>

    where the <with|mode|math|F<rsub|i>\<in\>\<cal-B\>(\<bbb-R\><rsup|n>)>.
  </definition>

  <subsection|Brownian Motion (Wiener Processes)>

  <\definition>
    A real-valued process <with|mode|math|X<rsub|t>> is called Gaussian if
    its finite dimensional distributions are
    Gaussian<with|mode|math|\<Leftrightarrow\>><with|mode|math|(X<rsub|t<rsub|1>>,\<ldots\>,X<rsub|t<rsub|k>>)\<sim\>\<cal-N\>(k)>.
  </definition>

  Remember: A random variable <with|mode|math|\<xi\>> in
  <with|mode|math|\<bbb-R\><rsup|k>> is called <em|normal (multinormal)> if
  there exists a vector <with|mode|math|m\<in\>\<bbb-R\><rsup|k>> and a
  symmetric non-negative <with|mode|math|k\<times\>k>-matrix
  <with|mode|math|R=(R<rsub|i j>)> such that

  <\equation*>
    \<varphi\>(\<lambda\>)\<assign\>E[e<rsup|i(\<xi\>,\<lambda\>)>]=e<rsup|i(m,\<lambda\>)-(R\<lambda\>,\<lambda\>)/2>
  </equation*>

  for all <with|mode|math|\<lambda\>\<in\>\<bbb-R\><rsup|k>>, where
  <with|mode|math|(\<cdot\>,\<cdot\>)> represents an inner product,
  <with|mode|math|m=E[\<xi\>]> and <with|mode|math|R=cov(\<xi\><rsub|i>,\<xi\><rsub|j>)>.

  <em|Independence:> Fact: <with|mode|math|Y=(Y<rsub|1>,\<ldots\>,Y<rsub|n>)>
  are normal vectors in <with|mode|math|\<bbb-R\><rsup|k>> with
  <with|mode|math|(m<rsub|i>,R<rsub|i>)>. Then elements of <with|mode|math|Y>
  are independent iff

  <\equation*>
    \<varphi\><rsub|\<lambda\>>(Y)=<big|prod><rsub|i=1><rsup|n>\<varphi\><rsub|\<lambda\><rsub|i>>(Y<rsub|i>),
  </equation*>

  where <with|mode|math|\<lambda\>=(\<lambda\><rsub|1>,\<ldots\>,\<lambda\><rsub|n>)>,
  where <with|mode|math|\<lambda\><rsub|i>\<in\>\<bbb-R\><rsup|n>>.

  Fact 2: <with|mode|math|\<zeta\>=(\<zeta\><rsub|1>,\<ldots\>,\<zeta\><rsub|m>)>
  is Gaussian iff for any <with|mode|math|\<lambda\>\<in\>\<bbb-R\><rsup|m>>,

  <\equation*>
    (\<zeta\>,\<lambda\>)=<big|sum>\<lambda\><rsub|i>\<zeta\><rsub|i>
  </equation*>

  is Gaussian in 1D.

  <\definition>
    Brownian motion <with|mode|math|W<rsub|t>> is a one-dimensional
    continuous Gaussian process with

    <\equation*>
      E[W<rsub|t>]=0,<space|1em>E[W<rsub|t>W<rsub|s>]=t\<wedge\>s\<assign\>min(t,s).
    </equation*>
  </definition>

  Alternative Definition:

  <\definition>
    <label|def:bm-def2>Brownian motion <with|mode|math|W<rsub|t>> is a
    Brownian motion iff

    <\enumerate>
      <item><with|mode|math|W<rsub|0>=0>

      <item><with|mode|math|><with|mode|math|\<forall\>t,s:W<rsub|t>-W<rsub|s>\<sim\>\<cal-N\>(0,t-s)>

      <item><with|mode|math|W<rsub|t<rsub|1>>>,
      <with|mode|math|W<rsub|t<rsub|2>>-W<rsub|t<rsub|1>>,\<ldots\>> are
      independent for all partitions <with|mode|math|t<rsub|1>\<less\>t<rsub|2>\<less\>t<rsub|3>\<less\>\<cdots\>>.
    </enumerate>
  </definition>

  Yet another:

  <\definition>
    The property (3) in Definition <reference|def:bm-def2> may be replaced by

    3<with|mode|math|<rprime|'>>. <with|mode|math|W<rsub|t<rsub|n>>-W<rsub|t<rsub|n-1>>>
    is independent of <with|mode|math|W<rsub|t<rsub|n-1>>-W<rsub|t<rsub|n-2>>>,<with|mode|math|\<ldots\>>
  </definition>

  <\definition>
    <\equation*>
      \<cal-F\><rsub|t><rsup|W>\<assign\>\<sigma\>({W<rsub|s<rsub|1>>,W<rsub|s<rsub|2>>,\<ldots\>:s<rsub|i>\<leqslant\>t}).
    </equation*>
  </definition>

  <\theorem>
    Brownian motion is a <em|martingale> w.r.t.
    <with|mode|math|\<cal-F\><rsub|t><rsup|W>><with|mode|math|\<Leftrightarrow\>>

    <\equation*>
      E[W<rsub|t>\|\<cal-F\><rsub|s><rsup|W>]=W<rsub|s>
    </equation*>

    for <with|mode|math|s\<less\>t>. (This is also the definition of a
    martingale.)
  </theorem>

  <\remark>
    <with|mode|math|\<sigma\>(W<rsub|t<rsub|1>>,W<rsub|t<rsub|2>>,\<ldots\>,W<rsub|t<rsub|n>>)=\<sigma\>(W<rsub|t<rsub|1>>,W<rsub|t<rsub|2>>-W<rsub|t<rsub|1>>,\<ldots\>,W<rsub|t<rsub|n>>-W<rsub|t<rsub|n-1>>)>
    (knowledge of one gives the other--add or subtract). This is important
    because RHS is independent, but LHS is not.
  </remark>

  <\corollary>
    \;

    <\enumerate>
      <item><with|mode|math|E[W<rsub|t><rsup|2>]=t>. (So
      <with|mode|math|W<rsub|t>> grows roughly as <with|mode|math|<sqrt|t>>.)

      <item><with|mode|math|W<rsub|t><rsup|2>/t\<rightarrow\>0> almost
      surely.

      Proof: By Chebyshev's inequality, <with|mode|math|P(\|W<rsub|t>/t\|\<gtr\>c)\<less\>E[\|W<rsub|t>/t\|<rsup|2>]/c<rsup|2>=t/t<rsup|2>c<rsup|2>\<rightarrow\>0>
      as <with|mode|math|t\<rightarrow\>\<infty\>>.
    </enumerate>
  </corollary>

  <em|Law of iterated logarithm:>\ 

  <\eqnarray*>
    <tformat|<table|<row|<cell|\<varphi\><rsub|t><rsup|0>=<frac|W<rsub|t>|<sqrt|2t*log
    log(1/t)>>,>|<cell|>|<cell|\<varphi\><rsub|t><rsup|\<infty\>>=<frac|W<rsub|t>|<sqrt|2t
    log log(t)>>,>>|<row|<cell|limsup<rsub|t\<rightarrow\>0>\<varphi\><rsub|t><rsup|0>=1,>|<cell|>|<cell|limsup<rsub|t\<rightarrow\>\<infty\>>\<varphi\><rsub|t><rsup|\<infty\>>=1,>>|<row|<cell|liminf<rsub|t\<rightarrow\>0>
    \<varphi\><rsub|t><rsup|0>=-1,>|<cell|>|<cell|liminf<rsub|t\<rightarrow\>\<infty\>>
    \<varphi\><rsub|t><rsup|\<infty\>>=-1.>>>>
  </eqnarray*>

  <em|Continuity and Differentiability:>

  <\itemize>
    <item><with|mode|math|W<rsub|t>> is continuous.

    <item><with|mode|math|W<rsub|t>> is nowhere differentiable.
  </itemize>

  <em|Spectral representation of Brownian motion:>

  <\theorem>
    \;

    <\eqnarray*>
      <tformat|<table|<row|<cell|W<rsub|t>>|<cell|=>|<cell|t\<eta\><rsub|0>+<big|sum><rsub|n=1><rsup|\<infty\>>\<eta\><rsub|n>sin(n*t)\<approx\>t*\<eta\><rsub|0>+<big|sum><rsub|n=1><rsup|N>\<eta\><rsub|n>sin(n*t),<space|1em><with|mode|text|where>>>|<row|<cell|\<eta\><rsub|n>>|<cell|\<sim\>>|<cell|\<cal-N\>(0,2/\<pi\>n<rsup|2>)
      <space|1em>(n\<geqslant\>1),>>|<row|<cell|\<eta\><rsub|0>>|<cell|\<sim\>>|<cell|\<cal-N\>(0,1/\<pi\>).>>>>
    </eqnarray*>
  </theorem>

  <\proof>
    Consider <with|mode|math|t\<in\>[0,\<pi\>]>.

    <\equation*>
      <wide|W<rsub|>|~><rsub|t>\<assign\>W<rsub|t>-<frac|t|\<pi\>>W<rsub|\<pi\>><space|1em><with|mode|text|for
      <with|mode|math|t\<in\>[0,\<pi\>]>>.
    </equation*>

    Then

    <\equation*>
      <wide|W|~>(t)=<big|sum><rsub|n=1><rsup|\<infty\>>\<eta\><rsub|n>sin(n*t),
    </equation*>

    where

    <\equation*>
      \<eta\><rsub|n>=<frac|2|\<pi\>><big|int><rsub|0><rsup|\<pi\>><wide|W|~>(t)sin(n*t)\<mathd\>t<space|1em>(n\<gtr\>0)
    </equation*>

    and

    <\equation*>
      \<eta\><rsub|0>=<frac|W(\<pi\>)|\<pi\>>.
    </equation*>

    First fact: <with|mode|math|\<eta\><rsub|n>> are Gaussian because linear
    combinations of normal r.v.s. are normal.

    <\equation*>
      E\<eta\><rsub|k>\<eta\><rsub|n>=<frac|4|\<pi\><rsup|2>><big|int><rsub|0><rsup|\<pi\>><big|int><rsub|0><rsup|\<pi\>>(t\<wedge\>s-t*s/\<pi\>)sin(n*t)sin(k*s)=<choice|<tformat|<table|<row|<cell|0>|<cell|k\<neq\>n,>>|<row|<cell|<frac|2|\<pi\>n<rsup|2>>>|<cell|k=n\<gtr\>0.>>>>>
    </equation*>

    For <with|mode|math|n=0>,

    <\equation*>
      E[\<eta\><rsub|0><rsup|2>]=E<frac|W<rsup|2>[\<pi\>]|\<pi\><rsup|2>>=<frac|1|\<pi\>>.
    </equation*>

    \;
  </proof>

  <section|The Itô Integral and Formula>

  Suppose we have some system described by <with|mode|math|X<rsub|t>> that
  has some additive noise <with|mode|math|\<xi\><rsub|t>>:
  <with|mode|math|Y<rsub|t>=X<rsub|t>+\<xi\><rsub|t>>.
  (<with|mode|math|t=1,2,3,\<ldots\>>) The
  <with|mode|math|\<xi\><rsub|1>,\<xi\><rsub|2>,\<ldots\>> are assumed to be

  <\enumerate>
    <item>iid

    <item><with|mode|math|\<xi\><rsub|i>\<sim\>N(\<mu\>,\<sigma\><rsup|2>)>
  </enumerate>

  If the <with|mode|math|\<xi\><rsub|t>> satisfy the first property, they are
  called <em|white noise>. If they satisfy both, it is <em|Gaussian white
  noise>.

  If we now consider <with|mode|math|W<rsub|t>>
  <with|mode|math|\<xi\><rsub|0>=W<rsub|0>=0>,
  <with|mode|math|\<xi\><rsub|1>=W<rsub|t<rsub|1>>-W<rsub|0>>,
  <with|mode|math|\<xi\><rsub|2>=W<rsub|t<rsub|2>>-W<rsub|t<rsub|1>>>, ...,
  then

  <\enumerate>
    <item>holds

    <item>holds
  </enumerate>

  A popular model in dynamics is

  <\equation*>
    X<rsub|t+\<Delta\>>=A*X<rsub|t>+B+\<xi\><rsub|t+1>
  </equation*>

  for, say, the dynamics of an ``aircraft''. Another possibility is modeling
  the price of a risky asset

  <\equation*>
    X<rsub|t+\<Delta\>>=X<rsub|t>+\<mu\>X<rsub|t>\<Delta\>+\<sigma\>X<rsub|t>(W<rsub|t+1>-W<rsub|t>),
  </equation*>

  where <with|mode|math|\<mu\>> is the individual trend of the stock, while
  <with|mode|math|\<sigma\>> is market-introduced volatility. Equivalently,
  we might write

  <\equation*>
    <frac|X<rsub|t+\<Delta\>>-X<rsub|t>|\<Delta\>>=\<mu\>X<rsub|t>-\<sigma\>X<rsub|t><frac|W<rsub|t+1>-W<rsub|t>|\<Delta\>>
  </equation*>

  and then let <with|mode|math|\<Delta\>t\<downarrow\>0>, such that we obtain

  <\equation*>
    <wide|X|\<dot\>><rsub|t>=\<mu\>X<rsub|t>+\<sigma\>X<rsub|t><wide|W|\<dot\>><rsub|t>,
  </equation*>

  which is all nice and well except that the derivative of white noise does
  not exist. But note that there is less of a problem defining the same
  equation in integral terms.

  <em|Step 1:> Suppose we have a function <with|mode|math|f(s)>, which might
  be random. Then define

  <\equation*>
    I<rsub|n>(f)=<big|sum><rsub|k>f(s<rsub|k><rsup|\<ast\>>)(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>).
  </equation*>

  But what happens if <with|mode|math|f(s)=W<rsub|s>>. We get the term

  <\equation*>
    W<rsub|s<rsub|k>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>).
  </equation*>

  Or is it

  <\equation*>
    W<rsub|s<rsub|k+1>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)?
  </equation*>

  Or even

  <\equation*>
    W<rsub|<frac|s<rsub|k+1>+s<rsub|k>|2>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)?
  </equation*>

  In the Riemann integral, it does not matter where you evaluate the
  integrand--it all converges to the same value. But here, we run into
  trouble. Consider

  <\eqnarray*>
    <tformat|<table|<row|<cell|E\|W<rsub|s<rsub|k>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)\|<rsup|2>>|<cell|\<neq\>>|<cell|E\|W<rsub|s<rsub|k+1>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)\|<rsup|2>>>|<row|<cell|\<\|\|\><space|2em>>|<cell|>|<cell|<space|2em><neg|\<\|\|\>>>>|<row|<cell|E\|W<rsub|s<rsub|k>>\|<rsup|2>E\|W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>\|<rsup|2>>|<cell|>|<cell|E\|W<rsub|s<rsub|k-1>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)\|<rsup|2>>>|<row|<cell|\<\|\|\><space|2em>>|<cell|>|<cell|<space|2em><neg|\<\|\|\>>>>|<row|<cell|s<rsub|k>(s<rsub|k+1>-s<rsub|k>)>|<cell|>|<cell|E\|W<rsub|<frac|s<rsub|k+1>+s<rsub|k>|2>>(W<rsub|s<rsub|k+1>>-W<rsub|s<rsub|k>>)\|<rsup|2>.>>>>
  </eqnarray*>

  <em|Problem:> Compute each of the above expectations, and show they are not
  equal.

  <subsection|The Itô Construction>

  The idea here is to use simple functions:

  <\equation*>
    f(s)=<big|sum><rsub|i=0><rsup|n>e<rsub|i>(\<omega\>)\<b-1\><rsub|(t<rsub|i>,t<rsub|i+1>)>(s),
  </equation*>

  where <with|mode|math|e<rsub|i>> is <with|mode|math|\<cal-F\><rsub|t<rsub|i>><rsup|W>>-measurable,
  where <with|mode|math|\<cal-F\><rsub|t<rsub|i>><rsup|W>=\<sigma\>(W<rsub|s<rsub|1>>,\<ldots\>,W<rsub|s<rsub|k>>:s<rsub|i>\<leqslant\>s)>

  <\eqnarray*>
    <tformat|<table|<row|<cell|>|<cell|\<Leftrightarrow\>>|<cell|>>|<row|<cell|>|<cell|e<rsub|i>=e<rsub|i>(W<rsub|r>,
    r\<in\>[0,t<rsub|i>])>|<cell|>>|<row|<cell|>|<cell|\<Leftrightarrow\>>|<cell|>>|<row|<cell|>|<cell|<with|mode|text|<with|mode|math|e<rsub|i>>
    is ``adapted'' to <with|mode|math|\<cal-F\><rsub|t<rsub|i>><rsup|W>>>.>|<cell|>>>>
  </eqnarray*>

  <\definition>
    <\equation*>
      I(f)=<big|sum><rsub|i=0><rsup|n>e<rsub|i>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>).
    </equation*>
  </definition>

  <em|Properties:>

  <\enumerate>
    <item><with|mode|math|E[I(f)]=0>

    <em|Proof:>\ 

    <\eqnarray*>
      <tformat|<table|<row|<cell|E[I(f)]>|<cell|=>|<cell|<big|sum><rsub|i=0><rsup|n>E*e<rsub|i>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)>>|<row|<cell|>|<cell|=>|<cell|<big|sum><rsub|i=0><rsup|n>E<left|(>E<left|(>e<rsub|i>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)<mid|\|>\<cal-F\><rsub|t<rsub|i>><rsup|W><right|)><right|)>>>|<row|<cell|>|<cell|=>|<cell|<big|sum><rsub|i=0><rsup|n>E(e<rsub|i>E[(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)\|\<cal-F\><rsub|t<rsub|i>><rsup|W>])>>|<row|<cell|>|<cell|=>|<cell|<big|sum><rsub|i=0><rsup|n>E(e<rsub|i>E[W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>])>>|<row|<cell|>|<cell|=>|<cell|<big|sum><rsub|i=0><rsup|n>E(e<rsub|i>*0)=0.>>>>
    </eqnarray*>

    <item>

    <\eqnarray*>
      <tformat|<table|<row|<cell|E\|I(f)\|<rsup|2>>|<cell|=>|<cell|<big|sum><rsub|i=1><rsup|N>E\|e<rsub|i>\|<rsup|2>(t<rsub|i+1>-t<rsub|i>)=<big|int><rsub|0><rsup|T>E\|f(s)\|<rsup|2>\<mathd\>s>>|<row|<cell|>|<cell|=>|<cell|E<left|[><big|sum>e<rsub|i>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)<right|]><rsup|2>>>|<row|<cell|>|<cell|=>|<cell|<big|sum>E<left|[>e<rsub|i><rsup|2>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)<rsup|2><right|]>-E<left|[>e<rsub|i>e<rsub|j>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)(W<rsub|t<rsub|j+1>>-W<rsub|t<rsub|j>>)<right|]>>>|<row|<cell|>|<cell|=>|<cell|E<left|(>E(e<rsub|i><rsup|2>(W<rsub|t<rsub|i+1>>-W<rsub|t<rsub|i>>)\|\<cal-F\><rsub|t<rsub|i>><rsup|W>))>>|<row|<cell|>|<cell|=>|<cell|E[e<rsub|i><rsup|2>](t<rsub|i+1>-t<rsub|i>).>>>>
    </eqnarray*>

    <item><with|mode|math|I(f)> is linear.
  </enumerate>

  Next: If <with|mode|math|f(s)> is only <with|mode|math|\<cal-F\><rsub|s><rsup|W>>-measurable
  (but not a step function), and if <with|mode|math|<big|int><rsub|0><rsup|T>E*f<rsup|2>(s)\<mathd\>s\<less\>\<infty\>><with|mode|math|\<Rightarrow\>>
  could be approximated by a sequence of step functions
  <with|mode|math|f<rsub|n>(s)\<rightarrow\>f(s)>.

  [Insert <with|font-family|tt|lecture6.pdf> here, courtesy of Mario.]

  <new-page>

  <subsection|Itô's Formula>

  Suppose we have a partition of a time interval <with|mode|math|(0,T)> as
  <with|mode|math|t<rsub|0>=0,t<rsub|1>,t<rsub|2>,\<ldots\>,t<rsub|n>=T>.
  <with|mode|math|\<Delta\>t<rsub|i>=t<rsub|i+1>-t<rsub|i>>. We assume
  <with|mode|math|max \<Delta\>t<rsub|i>\<rightarrow\>0>. Also, we assume we
  have a function

  <\equation*>
    f=f(t),<space|1em>\<Delta\>f<rsub|i>=f(t<rsub|i+1>)+f(t<rsub|i>).
  </equation*>

  <\enumerate-alpha>
    <item>If <with|mode|math|f=f(t)>, continuous, bounded variation. Then

    <\equation*>
      lim<rsub|max \<Delta\>t<rsub|i>\<rightarrow\>0><big|sum><rsub|i=0><rsup|n-1>\|\<Delta\>f<rsub|i>\|<rsup|2>=lim<rsub|max
      \<Delta\>t<rsub|i>\<rightarrow\>0>max<wide*|\|\<Delta\>f<rsub|i>\||\<wide-underbrace\>><rsub|\<rightarrow\>0><wide*|<big|sum><rsub|i=0><rsup|n-1>\|\<Delta\>f<rsub|i>\||\<wide-underbrace\>><rsub|<with|mode|text|variation>\<rightarrow\><with|mode|text|bounded>>=0.
    </equation*>

    <item>If <with|mode|math|W=W(t)> is Standard Brownian Motion, then

    <\equation*>
      lim<rsub|max \<Delta\>t<rsub|i>><big|sum><rsub|i=0><rsup|n-1>\|\<Delta\>W<rsub|i>\|<rsup|2>=T<space|1em>(<with|mode|text|in
      <with|mode|math|L<rsup|2>> and in probability>).
    </equation*>

    <\proof>
      We need <with|mode|math|E\|<big|sum>\|\<Delta\>W<rsub|i>\|<rsup|2>\|-T\|<rsup|2>\<rightarrow\>0>.
      So

      <\eqnarray*>
        <tformat|<table|<row|<cell|>|<cell|>|<cell|E<left|(><left|(><big|sum><rsub|i>(\<Delta\>W<rsub|i>)<rsup|2><right|)><rsup|2>-2<big|sum><rsub|i>(\<Delta\>W<rsub|i>)<rsup|2>T+T<rsup|2><right|)>>>|<row|<cell|>|<cell|=>|<cell|E<left|[><big|sum><rsub|i,j>\|\<Delta\>W<rsub|i>\|<rsup|2>\|\<Delta\>W<rsub|j>\|<rsup|2>-2T<rsup|2>+T<rsup|2><right|]>>>|<row|<cell|>|<cell|=>|<cell|E<left|[><big|sum><rsub|i=0><rsup|n-1>\|\<Delta\>W<rsub|i>\|<rsup|4>+<big|sum><rsub|i\<neq\>j>\|\<Delta\>W<rsub|i>\|<rsup|2>\|\<Delta\>W<rsub|j>\|<rsup|2>-T<rsup|2><right|]>>>|<row|<cell|>|<cell|=>|<cell|3<big|sum><rsub|i>\|\<Delta\>t<rsub|i>\|<rsup|2>+<big|sum><rsub|i\<neq\>j>\<Delta\>t<rsub|i>\<Delta\>t<rsub|j>-T<rsup|2>>>|<row|<cell|>|<cell|=>|<cell|2<big|sum><rsub|i>\|\<Delta\>t<rsub|i>\|<rsup|2>+<wide*|<left|(><big|sum><rsub|i>\|\<Delta\>t<rsub|i>\|<right|)><rsup|2>|\<wide-underbrace\>><rsub|T<rsup|2>>-T<rsup|2>>>|<row|<cell|>|<cell|=>|<cell|2<big|sum><rsub|i>\|\<Delta\>t<rsub|i>\|<rsup|2>\<leqslant\>2max{\<Delta\>t<rsub|i>}\<cdot\>T\<rightarrow\>0.>>>>
      </eqnarray*>
    </proof>

    So we essentially showed:

    <\eqnarray*>
      <tformat|<table|<row|<cell|<big|sum><rsub|i=0><rsup|n-1>\|\<Delta\>W<rsub|i>\|<rsup|2>>|<cell|\<rightarrow\>>|<cell|T,>>|<row|<cell|(\<mathd\>W)<rsup|2>>|<cell|\<rightarrow\>>|<cell|\<mathd\>t,>>|<row|<cell|\<mathd\>W>|<cell|\<rightarrow\>>|<cell|<sqrt|\<mathd\>t>.<space|1em>(<with|mode|text|not
      rigorous>)>>>>
    </eqnarray*>
  </enumerate-alpha>

  <subsubsection|Deriving from the Chain Rule>

  if <with|mode|math|x=x(t)\<in\>C<rsup|1>> and
  <with|mode|math|F=F(y)\<in\>C<rsup|1>>. Then

  <\equation*>
    <frac|\<mathd\>|\<mathd\>t>F(x(t))=F<rprime|'>(x(t))x<rprime|'>(t).
  </equation*>

  Alternatively,

  <\equation*>
    x(t)=x(0)+<big|int><rsub|0><rsup|t><wide*|f(s)|\<wide-underbrace\>><rsub|x<rprime|'>(s)>\<mathd\>s.
  </equation*>

  Then

  <\equation*>
    F(x(t))=F(x(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(x(s))f(s)\<mathd\>s.
  </equation*>

  First of all, there is no ``Stratonovich Formula''. Suppose
  <with|mode|math|W<rsup|n>\<rightrightarrows\>W> (double arrows: uniformly),
  then

  <\eqnarray*>
    <tformat|<table|<row|<cell|X<rsup|n>(t)>|<cell|=>|<cell|X(0)+<wide*|<big|int><rsub|0><rsup|t>A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>B(s)<wide|W<rsup|n>|\<dot\>>(s)\<mathd\>s|\<wide-underbrace\>><rsub|=<big|int><rsub|0><rsup|t>(X<rsup|n>)<rprime|'>(s)\<mathd\>s>,>>|<row|<cell|X(t)>|<cell|=>|<cell|X(0)+<big|int><rsub|0><rsup|t>A(s)\<mathd\>s+<wide*|<big|int><rsub|0><rsup|t>B(s)\<circ\>\<mathd\>W(s)|\<wide-underbrace\>><rsub|<with|mode|text|Stratonovich
    Int.>>.>>|<row|<cell|F(X<rsup|n>(t))>|<cell|=>|<cell|F(X(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(X<rsup|n>(s))A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>F<rprime|'>(X<rsup|n>(s))B(s)<wide|W<rsup|n>|\<dot\>>(s)\<mathd\>s>>|<row|<cell|F(X(t))>|<cell|=>|<cell|F(X(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))B(s)\<circ\>(s)\<mathd\>W(s).>>>>
  </eqnarray*>

  In particular,

  <\equation*>
    X=W(t)=<big|int><rsub|0><rsup|t>1\<circ\>\<mathd\>W(s),<space|1em>F(y)=y<rsup|2>,<space|1em><big|int><rsub|0><rsup|t>W(s)\<circ\>\<mathd\>W(s)=<frac|1|2>W<rsup|2>(t).
  </equation*>

  <\remark>
    Itô integral is a martingale, Stratonovich is <em|not>. Also: there is no
    connection between the two in the non-smooth case.
  </remark>

  Now, let's see what happens for Itô, again starting from a process
  <with|mode|math|X(t)> given as

  <\eqnarray*>
    <tformat|<table|<row|<cell|X(t)>|<cell|=>|<cell|X(0)+<big|int><rsub|0><rsup|t>A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>B(s)\<mathd\>W(s).>>>>
  </eqnarray*>

  Now, what is <with|mode|math|F(X(t))>? Let's look at a Taylor expansion of

  <\equation*>
    F(X(t<rsub|i+1>))-F(X(t<rsub|i>))=F<rprime|'>(X(t<rsub|i>))\<Delta\>x<rsub|i>+<frac|1|2>F<rprime|''>(X(t<rsub|i>))(\<Delta\>x<rsub|i>)<rsup|2>+(\<cdots\>)<wide*|(\<Delta\>x<rsub|i>)<rsup|3>|\<wide-underbrace\>><rsub|\<sim\>(\<Delta\>t)<rsup|3/2>>
  </equation*>

  So, in continuous time

  <\eqnarray*>
    <tformat|<table|<row|<cell|F(X(t))>|<cell|=>|<cell|<big|sum>\<Delta\>F>>|<row|<cell|>|<cell|=>|<cell|F(X(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))\<mathd\>X(s)+<frac|1|2><big|int><rsub|0><rsup|t>F<rprime|''>(X(s))(\<mathd\>X(s))<rsup|2>>>|<row|<cell|>|<cell|=>|<cell|F(X(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))B(s)\<mathd\>W(s)+<frac|1|2><big|int><rsub|0><rsup|t>F<rprime|''>(X(s))B<rsup|2>(s)\<mathd\>s>>>>
  </eqnarray*>

  <\theorem>
    If

    <\equation*>
      X(t)=X(0)+<big|int><rsub|0><rsup|t>A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>B(s)\<mathd\>W(s)
    </equation*>

    and <with|mode|math|F\<in\>C<rsup|3>>, then

    <\equation*>
      F(X(t))=F(X(0))+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>F<rprime|'>(X(s))B(s)\<mathd\>W(s)+<frac|1|2><big|int><rsub|0><rsup|t>F<rprime|''>(X(s))B<rsup|2>(s)\<mathd\>s.
    </equation*>
  </theorem>

  Now if <with|mode|math|F\<in\>C<rsup|3>(\<bbb-R\><rsup|n>,\<bbb-R\><rsup|n>)>,then

  <\equation*>
    X(t)=X(0)+<big|int><rsub|0><rsup|t>A(s)\<mathd\>s+<big|int><rsub|0><rsup|t>B(s)\<mathd\>W(s)\<in\>\<bbb-R\><rsup|n>,
  </equation*>

  where we recall that <with|mode|math|W\<in\>\<bbb-R\><rsup|p>> with all
  <with|mode|math|p> components independent. Itô's Formula in multiple
  dimensions takes the form

  <\equation*>
    F<rsub|k>(X(t))=F<rsub|k>(X(0))+<big|int><rsub|0><rsup|t><big|sum><rsub|i><frac|\<partial\>F<rsub|k>|\<partial\>x<rsub|i>>A<rsub|i>\<mathd\>s+<big|sum><rsub|i,l><big|int><rsub|0><rsup|t><frac|\<partial\>F<rsub|k>|\<partial\>x<rsub|i>>B<rsub|i,l>\<mathd\>W<rsub|l>+<frac|1|2><big|int><rsub|0><rsup|t><big|sum><rsub|i,j><frac|\<partial\>F<rsub|k>|\<partial\>x<rsub|i>\<partial\>x<rsub|j>><big|sum><rsub|l>B<rsub|i
    l>B<rsub|j l>\<mathd\>s.
  </equation*>

  <\example>
    If <with|mode|math|F(x)=x<rsup|2> > and

    <\equation*>
      X=<big|int><rsub|0><rsup|t>\<mathd\>W(s),
    </equation*>

    then

    <\equation*>
      <big|int><rsub|0><rsup|t>W(s)\<mathd\>W(s)=<frac|1|2>(W<rsup|2>(t)-t).
    </equation*>
  </example>

  <\example>
    If <with|mode|math|\<Delta\>F=0> (i.e. <with|mode|math|F> is harmonic),
    then <with|mode|math|F(W(t))> is a martingale.
  </example>

  <subsubsection|SODEs>

  <\equation*>
    X(t)=X(0)+<big|int><rsub|0><rsup|t>b(s,X(s))\<mathd\>s+<big|int><rsub|0><rsup|t>\<sigma\>(s,X(s))\<mathd\>W(s)
  </equation*>

  or, equivalently

  <\equation*>
    \<mathd\>X=b(t,X)\<mathd\>t+\<sigma\>(t,X)\<mathd\>W(t).
  </equation*>

  <\example>
    <em|Ornstein-Uhlenbeck Process>. The equation

    <\equation*>
      \<mathd\>X(t)=a*X(t)\<mathd\>t+b*\<mathd\>W(t)
    </equation*>

    has the solution

    <\equation*>
      X(t)=e<rsup|a*t>X(0)+b<big|int><rsub|0><rsup|t>e<rsup|a(t-s)>\<mathd\>W(s).
    </equation*>

    <\proof>
      Consider

      <\eqnarray*>
        <tformat|<table|<row|<cell|X<rsub|t>>|<cell|=>|<cell|e<rsup|a*t>X(0)+b<big|int><rsub|0><rsup|t>e<rsup|a(t-s)>\<mathd\>W<rsub|s>>>|<row|<cell|>|<cell|=>|<cell|e<rsup|a*t>X(0)+b*e<rsup|a*t><big|int><rsub|0><rsup|t>e<rsup|-a*s>\<mathd\>W<rsub|s>>>|<row|<cell|>|<cell|=>|<cell|e<rsup|a*t>X(0)+b*e<rsup|a*t>Z<rsub|t>>>|<row|<cell|>|<cell|=>|<cell|g(t,Z<rsub|t>)<space|1em><with|mode|text|with><space|1em>\<mathd\>Z<rsub|t>=e<rsup|-a*t>\<mathd\>W<rsub|t>.>>>>
      </eqnarray*>

      Ito's Formula then gives

      <\eqnarray*>
        <tformat|<table|<row|<cell|\<mathd\>X<rsub|t>>|<cell|=>|<cell|<frac|\<partial\>g|\<partial\>t>\<mathd\>t+<frac|\<partial\>g|\<partial\>x>\<mathd\>Z<rsub|t>+<frac|1|2><frac|\<partial\><rsup|2>g|\<partial\>x<rsup|2>>(\<mathd\>Z<rsub|t>)<rsup|2>>>|<row|<cell|>|<cell|=>|<cell|X(0)a*e<rsup|a*t>+b*e<rsup|a*t>\<mathd\>Z<rsub|t>+0>>|<row|<cell|>|<cell|=>|<cell|X(0)a*e<rsup|a*t>+b*e<rsup|a*t>e<rsup|-a*t>\<mathd\>W<rsub|t>>>|<row|<cell|>|<cell|=>|<cell|X(0)a*e<rsup|a*t>+b*\<mathd\>W<rsub|t>.>>>>
      </eqnarray*>
    </proof>
  </example>

  <\example>
    (<em|Geometric Brownian Motion>)

    <\equation*>
      \<mathd\>X(t)=a*X(t)\<mathd\>t+b*X(t)\<mathd\>W(t)
    </equation*>

    is solved by

    <\equation*>
      X(t)=X(0)e<rsup|(a-b<rsup|2>/2)t+b*W(t)>.
    </equation*>

    (Check this by Itô.)
  </example>

  <em|Homework:> Solve

  <\equation*>
    \<mathd\>X(t)=(a<rsub|1>+a<rsub|2>X(t))\<mathd\>t+(b<rsub|1>+b<rsub|2>X)\<mathd\>W(t).
  </equation*>

  <\theorem>
    If <with|mode|math|\|b<rsub|i>(s,x)-b<rsub|i>(s,y)\|+\|\<sigma\><rsub|i,k>(s,x)-\<sigma\><rsub|i,k>(s,y)\<leqslant\>C\|x-y\|>
    (a Lipschitz condition) and <with|mode|math|\|b<rsub|i>(s,x)\|+\|\<sigma\><rsub|i,k>(s,x)\|\<leqslant\>C(1+\|X\|)>
    (a linear growth condition) and <with|mode|math|X(0)> is independent of
    <with|mode|math|W> and <with|mode|math|E\|X(0)\|<rsup|2>\<less\>\<infty\>>,
    then there exists a solution <with|mode|math|X(t)> that is continuous in
    time. <with|mode|math|X(t)> is measurable w.r.t
    <with|mode|math|\<sigma\>(X(0),W(s),s\<leqslant\>t)> and

    <\equation*>
      E<left|[>sup<rsub|t\<leqslant\>T>\|X(t)\|<rsup|2><right|]>\<less\>\<infty\>.
    </equation*>
  </theorem>

  <section|Some SPDEs>

  <\equation*>
    u<rsub|t>=a*u<rsub|x x>,<space|1em>u(0,x)=u<rsub|0>(x).
  </equation*>

  (<with|mode|math|a\<gtr\>0>--ellipticity: if it holds, then the equation is
  called parabolic) General solution:

  <\equation*>
    u(t,x)=<frac|1|<sqrt|4\<pi\>*a*t>><big|int><rsub|R>exp<left|(>-<frac|2\|x-y\|<rsup|2>|4*a*t><right|)>u<rsub|0>(y)\<mathd\>y=E[u<rsub|0>(x+<sqrt|2\<pi\>>W(t)]
  </equation*>

  (<em|Feynman-Kac> formula--averaging over characteristics)

  Monte-Carlo simulation:

  <\equation*>
    area(A)=<frac|<with|mode|text|#hits in a set
    <with|mode|math|A>>|<with|mode|text|#hits in a surrounding square>>.
  </equation*>

  More general parabolic equation:

  <\equation*>
    u<rsub|t>(x,t)=a<rsub|i j>D<rsub|i>D<rsub|j>u(x,t)+b<rsub|i>D<rsub|i>u(x,t)+c*u+f<space|1em>(t\<gtr\>0,x\<in\>\<bbb-R\><rsup|d>)<space|1em>u(0,x)=u<rsub|0>(x)
  </equation*>

  This equation is parabolic iff <with|mode|math|a<rsub| i j>y<rsub|i>
  y<rsub|j>\<geqslant\>a\|y\|<rsup|2>> for all
  <with|mode|math|y\<in\>\<bbb-R\><rsup|d>> (the ellipticity property). If
  the highest order partial differential operator in the equation is
  elliptic, then the equation is parabolic. (The elliptic equation would be

  <\equation*>
    a<rsub|i j>D<rsub|i>D<rsub|j>u(x,t)+b<rsub|i>D<rsub|i>u(x,t)+c*u+f=0.)
  </equation*>

  Now, onwards to <em|Stochastic> PDEs. A model equation is

  <\equation*>
    \<mathd\>u(t,x)=a*u<rsub|x x>(t,x)\<mathd\>t+\<sigma\>u<rsub|x>(t,x)\<mathd\>W<rsub|t>.
  </equation*>

  Recall from geometric Brownian motion:

  <\equation*>
    \<mathd\>u(t)=a*u(t)\<mathd\>t+\<sigma\>u(t)\<mathd\>W<rsub|t>,<space|1em>u(0)=0.
  </equation*>

  The solution is

  <\equation*>
    u(t)=u<rsub|0>exp<left|(><left|(>a-<frac|\<sigma\><rsup|2>|2><right|)>+\<sigma\>W<rsub|t><right|)>
  </equation*>

  and

  <\equation*>
    E[u<rsup|2>(t)]=u<rsub|0><rsup|2>exp{u*t}E[exp<left|{>2\<sigma\>W<rsub|t>-\<sigma\><rsup|2>t<rsup|2><right|}>].
  </equation*>

  Now consider

  <\equation*>
    E<left|[><wide*|exp<left|(>b*W<rsub|t>-<frac|1|2>b<rsup|2>t<right|)>|\<wide-underbrace\>><rsub|\<rho\>(t)><right|]>=1,
  </equation*>

  which is an example of an <em|exponential martingale>, which satisfies the
  general property

  <\equation*>
    E[\<rho\>(t)\|\<cal-F\><rsub|s><rsup|W>]=\<rho\>(s)<space|1em><with|mode|text|for><space|1em>s\<less\>t,<space|1em>\<rho\>(0)=1.
  </equation*>

  We find

  <\equation*>
    E(\<rho\>(t)]=E[\<rho\>(s)]=E[\<rho\>(0)]=1.
  </equation*>

  <\proof>
    By Ito's formula,

    <\equation*>
      \<mathd\>\<rho\>(t)=b\<rho\>(t)\<mathd\>W<rsub|t><space|1em>\<Rightarrow\><space|1em>\<rho\>(t)=1+b<big|int><rsub|0><rsup|t>\<rho\>(s)\<mathd\>W<rsub|s>.
    </equation*>

    \;
  </proof>

  Here's a crude analogy: In stochastic analysis, <with|mode|math|\<rho\>(t)>
  plays the role of <with|mode|math|exp(t)> in ``regular'' real analysis.
  Going back to our above computation, we find

  <\equation*>
    E[u<rsup|2>(t)]=u<rsub|0><rsup|2>exp{u*t}E[exp<left|{>2\<sigma\>W<rsub|t>-\<sigma\><rsup|2>t<rsup|2><right|}>]=u<rsub|0>exp<left|{>2a*t<right|}>.
  </equation*>

  So we find for geometric Brownian motion that it remains square-integrable
  for all time. (Consider that this is also the case for the regular heat
  equation.) Now, let's return to our SPDE,

  <\equation*>
    \<mathd\>u(t,x)=a*u<rsub|x x>(t,x)\<mathd\>t+\<sigma\>u<rsub|x>(t,x)\<mathd\>W<rsub|t>.
  </equation*>

  We begin by applying the Fourier transform to <with|mode|math|u>, yielding
  <with|mode|math|<wide|u|^>>.

  <\equation*>
    \<mathd\><wide|u|^>=-a*y<rsup|2><wide|u|^>+i\<sigma\>y<wide|u|^>(t,y)\<mathd\>W<rsub|t>
  </equation*>

  <\equation*>
    <wide|u|^>=<wide|u|^>(0,y)exp(-<left|(>a-\<sigma\><rsup|2>/2)y<rsup|2>t<right|)>+i*y\<sigma\>W<rsub|t>).
  </equation*>

  Parseval's equality tells us

  <\equation*>
    <big|int>\|u(t,x)\|<rsup|2>=<big|int>\|<wide|u|^>(t,y)\|<rsup|2>\<mathd\>y\<less\>\<infty\>
  </equation*>

  iff <with|mode|math|a-\<sigma\><rsup|2>/2\<gtr\>0>. In SPDEs, first order
  derivatives in stochastic terms has the same strength as the second
  derivative in deterministic terms. The above condition is also called
  <em|super-ellipticity>, and the whole evolution equation is then called
  <em|super-parabolic>.

  There's another example of SPDE in the lecture notes:

  <\equation*>
    \<mathd\>u(t,x)=a*u<rsub|x x>(t,x)\<mathd\>t+\<sigma\>u(t,x)\<mathd\>W<rsub|t>.
  </equation*>

  Here, the superellipticity equation is

  <\equation*>
    a-<frac|0<rsup|2>|2>\<gtr\>0<space|1em>\<Leftrightarrow\><space|1em>a\<gtr\>0.
  </equation*>

  For the homework, see the notes as well. One of these problems is to
  consider the more general equation

  <\equation*>
    \<mathd\>u=a<rsub|i j>D<rsub|i>D<rsub|j>u+b<rsub|i>D<rsub|i>u+c*u\<mathd\>t+(\<sigma\><rsub|i
    k>D<rsub|i>u+\<nu\><rsub|k>)\<mathd\>W<rsub|k>(t)<space|1em>i,j=1,\<ldots\>,d,<space|1em>k=1,2,3,\<ldots\>
  </equation*>

  where we have

  <\equation*>
    \<sigma\>=<matrix|<tformat|<table|<row|<cell|\<sigma\><rsub|11>>|<cell|\<sigma\><rsub|12>>|<cell|\<cdots\>>>|<row|<cell|\<vdots\>>|<cell|>|<cell|>>|<row|<cell|\<sigma\><rsub|d1>>|<cell|\<sigma\><rsub|d2>>|<cell|\<cdots\>>>>>>.
  </equation*>

  We have to assume

  <\equation*>
    \<sigma\>\<sigma\><rsup|\<ast\>>=<big|sum><rsub|k=1><rsup|\<infty\>>\<sigma\><rsub|i
    k>\<sigma\><rsub|j k>\<less\>\<infty\>,<space|1em><big|sum><rsub|k>\<nu\><rsub|k><rsup|2>\<less\>\<infty\>.
  </equation*>

  <\equation*>
    \;
  </equation*>

  A substitution that sometimes helps in the deterministic case is
  illustrated below:

  <\equation*>
    <frac|\<partial\>u|\<partial\>t>=a(t,x)u<rsub|x x>+c*u
  </equation*>

  Then we set <with|mode|math|v(t,x)=e<rsup|-c*t>u(t,x)> and obtain

  <\equation*>
    \<mathd\>v(t,x)=-c*e<rsup|-c*t>u(t,x)+a(t,x)*e<rsup|-c*t>u<rsub|x
    x>+c*e<rsup|-c*t>u=a(t,x)u*v<rsub|x x>.
  </equation*>

  For the stochastic case, note:

  <\equation*>
    \<mathd\>\<rho\>(t)=\<rho\>(t)\<sigma\>\<mathd\>W<rsub|t>.
  </equation*>

  Then, let

  <\eqnarray*>
    <tformat|<table|<row|<cell|\<eta\>(t)>|<cell|\<assign\>>|<cell|e<rsup|-\<sigma\>W(t)-(\<sigma\><rsup|2>/2)t>>>|<row|<cell|\<mathd\>\<eta\>(t)>|<cell|=>|<cell|-\<eta\>(t)\<sigma\>\<mathd\>\<Omega\><rsub|t>>>|<row|<cell|\<rho\><rsup|-1>(t)>|<cell|=>|<cell|\<eta\>(t)exp(\<sigma\><rsup|2>t)>>|<row|<cell|\<mathd\>\<rho\><rsup|-1>(t)>|<cell|=>|<cell|-\<eta\>(t)\<sigma\>\<mathd\>W<rsub|t>exp(\<sigma\><rsup|2>t)+\<eta\>(t)exp(\<sigma\><rsup|2>t)\<sigma\><rsup|2>\<mathd\>t=-\<rho\><rsup|-1>\<sigma\>\<mathd\>W<rsub|t>+\<sigma\><rsup|2>\<rho\><rsup|-1>(t)\<mathd\>t>>>>
  </eqnarray*>

  Applied to an SPDE, we get

  <\eqnarray*>
    <tformat|<table|<row|<cell|\<mathd\>u(t,x)>|<cell|=>|<cell|a*u(t,x)\<mathd\>t+\<sigma\>u(t,x)\<mathd\>W<rsub|t>>>|<row|<cell|u(0,x)>|<cell|=>|<cell|u<rsub|0>>>|<row|<cell|v(t,x)>|<cell|=>|<cell|<wide*|e<rsup|-\<sigma\>W(t)+(\<sigma\><rsup|2>/2)t>|\<wide-underbrace\>><rsub|\<rho\><rsup|-1>(t)>u(t,x)>>|<row|<cell|\<mathd\>(u(t,x)\<rho\><rsup|-1>(t))>|<cell|=>|<cell|a*v<rsub|x
    x>\<mathd\>t+\<sigma\>v\<mathd\>W<rsub|t>-v\<sigma\>\<mathd\>W<rsub|t>+\<sigma\><rsup|2>v\<mathd\>t-\<sigma\><rsup|2>v\<mathd\>t>>|<row|<cell|>|<cell|=>|<cell|a*v<rsub|x
    x>\<mathd\>t.>>>>
  </eqnarray*>

  Let <with|mode|math|<wide|W|~>(t)> be a Wiener process independent of
  <with|mode|math|W>.

  <\eqnarray*>
    <tformat|<table|<row|<cell|v(t,x)>|<cell|=>|<cell|E<left|[>u<rsub|0><left|(>t+<sqrt|2a><wide|W|~><rsub|t><right|)><right|]>.>>>>
  </eqnarray*>

  Then

  <\eqnarray*>
    <tformat|<table|<row|<cell|u(t,x)>|<cell|=>|<cell|E<left|[>u<rsub|0><left|(>x+<sqrt|2a><wide|W|~><rsub|t><right|)><right|]>exp(\<sigma\><rsup|2>W<rsub|t>-(\<sigma\><rsup|2>/2)t>>|<row|<cell|>|<cell|=>|<cell|E<left|[>u<rsub|0><left|(>x+<sqrt|2a><wide|W|~><rsub|t><right|)>exp(\<sigma\><rsup|2>W<rsub|t>-(\<sigma\><rsup|2>/2)t<mid|\|>\<cal-F\><rsub|t><rsup|W><right|]>.>>>>
  </eqnarray*>

  <\example>
    Now consider

    <\equation*>
      \<mathd\>u(t,x)=a*u<rsub|x x>(t,x)+\<sigma\>u<rsub|x>(t,x)\<mathd\>W<rsub|t><space|1em>\<Leftrightarrow\><space|1em>2a-\<sigma\><rsup|2>\<gtr\>0.
    </equation*>

    (Remark: There is not a chance to reduce to
    <with|mode|math|\<partial\><rsub|t><wide|u|~>=a<wide|u|~><rsub|x x>>.)

    <\eqnarray*>
      <tformat|<table|<row|<cell|<frac|\<partial\>v|\<partial\>t>>|<cell|=>|<cell|(a-\<sigma\><rsup|2>/2)v<rsub|x
      x>(t)>>|<row|<cell|u(t,x)>|<cell|=>|<cell|v(t,x+\<sigma\>W(t))<space|1em><with|mode|text|then><space|1em><with|mode|text|<with|mode|math|u>
      verifies equation>.>>>>
    </eqnarray*>
  </example>

  <\eqnarray*>
    <tformat|<table|<row|<cell|v(t,x)>|<cell|=>|<cell|E<left|[>u<rsub|0><left|(>x+<sqrt|2a-\<sigma\><rsup|2>><wide|W|~>(t)<right|)><right|]>>>|<row|<cell|>|<cell|\<Downarrow\>>|<cell|>>|<row|<cell|u(t,x)>|<cell|=>|<cell|E<left|[>u<rsub|0><left|(>x+W<rsub|t>+<sqrt|2a-\<sigma\><rsup|2>><wide|W|~><rsub|t><right|)><mid|\|>\<cal-F\><rsub|t><rsup|W><right|]>.>>>>
  </eqnarray*>

  (Note that, as above, the point of the conditional expectation is not
  measurability w.r.t. time (...), but with respect to <with|mode|math|W> and
  not w.r.t. <with|mode|math|<wide|W|~>>.) By a naive application of Ito's
  formula, we would get

  <\eqnarray*>
    <tformat|<table|<row|<cell|u(t,x)>|<cell|=>|<cell|v(t,x+\<sigma\>W<rsub|t>)>>|<row|<cell|v(t,x)>|<cell|=>|<cell|u(t,x-\<sigma\>W<rsub|t>)>>|<row|<cell|\<mathd\>u(t,x-\<sigma\>W<rsub|t>)>|<cell|=>|<cell|\<sigma\><rsup|2>/2u<rsub|x
    x>(t,x-\<sigma\>W<rsub|t>)>>|<row|<cell|-\<sigma\>u<rsub|x>(t,x-\<sigma\>W<rsub|t>)\<mathd\>W<rsub|t>>|<cell|=>|<cell|<frac|\<sigma\><rsup|2>|2>v<rsub|x
    x>\<mathd\>t-\<sigma\>v<rsub|x>\<mathd\>W<rsub|t>.>>>>
  </eqnarray*>

  But this is wrong because Ito's formula only applies to <em|deterministic>
  functions of brownian motion. The function <with|mode|math|u> itself is
  random, though, so it does not work. To the rescue, the Ito-Wentzell
  formula.

  <\theorem>
    <dueto|Ito-Wentzell>Suppose

    <\equation*>
      \<mathd\>F(t,x)=J(t,x)\<mathd\>t+H(t,x)\<mathd\>W<rsub|t>
    </equation*>

    and

    <\equation*>
      \<mathd\>Y(t)=b(t)\<mathd\>t+\<sigma\>(\<tau\>)\<mathd\>W<rsub|t>.
    </equation*>

    Then

    <\equation*>
      \<mathd\>F(t,Y(t))=<wide*|J(Y(t))\<mathd\>t+H(Y(t))\<mathd\>W<rsub|t>|\<wide-underbrace\>><rsub|\<mathd\><rsub|t>F>+F<rsub|x>(Y(t))b\<mathd\>t+<frac|\<sigma\><rsup|2>|2>F<rsub|x
      x>(Y(t))\<mathd\>t+\<sigma\>F<rsub|x>(Y(t))\<mathd\>W<rsub|t>
      +H<rsub|x>(t,Y(t))\<sigma\>(t)\<mathd\>t
    </equation*>

    For comparison, if we suppose <with|mode|math|\<mathd\>G(t,x)=J(t,x)\<mathd\>t>
    and work out the regular Ito formula, we would find

    <\equation*>
      \<mathd\>G(t,Y(t))=<wide*|J(t,Y(t))\<mathd\>t|\<wide-underbrace\>><rsub|\<mathd\><rsub|t>G>+G<rsub|x>(Y(t))b(t)\<mathd\>t+<frac|1|2>G<rsub|x
      x>\<sigma\><rsup|2>\<mathd\>t+G<rsub|x>(Y)\<mathd\>W<rsub|t>.
    </equation*>
  </theorem>

  <section|PDE/Sobolev Recap>

  <\itemize>
    <item>Spaces: <with|mode|math|H<rsub|2><rsup|\<gamma\>>=H<rsub|2><rsup|\<gamma\>>(\<bbb-R\><rsup|d>)>

    <item>Heat equation: <with|mode|math|H<rsub|2><rsup|\<gamma\>>>,
    <with|mode|math|L<rsub|2>(\<bbb-R\><rsup|d>)>,
    <with|mode|math|H<rsub|2><rsup|-1>>.

    <item>an SPDE: <with|mode|math|H<rsub|2><rsup|\<gamma\>>>,
    <with|mode|math|L<rsub|2>(\<bbb-R\><rsup|d>)>,
    <with|mode|math|H<rsub|2><rsup|-1>>.
  </itemize>

  We will need:

  <\itemize>
    <item>Gronwall Inequality: ...

    <item>BDG Inequality (<with|mode|math|p=1>)

    <\equation*>
      E<left|\|>sup<rsub|t\<leqslant\>T><big|int><rsub|0><rsup|t>g(s)\<mathd\>W<rsub|s><right|\|>\<leqslant\>C*E<left|\|><big|int><rsub|0><rsup|T>g<rsup|2>(t)\<mathd\>t<right|\|><rsup|1/2>.
    </equation*>

    <item><with|mode|math|\<varepsilon\>>-inequality

    <\equation*>
      \|a*b\|\<leqslant\>\<varepsilon\>a<rsup|2>+<frac|1|\<varepsilon\>>b<rsup|2>.
    </equation*>

    <item>Itô-Wentzell formula.
  </itemize>

  <subsection|Sobolev Spaces <with|mode|math|H<rsub|2><rsup|\<gamma\>>>>

  <\definition>
    Suppose <with|mode|math|f\<in\>C<rsub|0><rsup|\<infty\>>(\<bbb-R\><rsup|d>)>.
    Then

    <\equation*>
      <wide|f|^>(y)=<frac|1|(2\<pi\>)<rsup|d/2>><big|int><rsub|\<bbb-R\><rsup|d>>e<rsup|-i*x*y>f(x)\<mathd\>x.
    </equation*>
  </definition>

  Then we have Parseval's Inequality

  <\equation*>
    <big|int><rsub|\<bbb-R\><rsup|d>>\|f\|<rsup|2>\<mathd\>x=<big|int><rsub|\<bbb-R\><rsup|d>>\|<wide|f|^>\|<rsup|2>\<mathd\>y
  </equation*>

  and define

  <\equation*>
    <norm|f|\<gamma\>|>\<assign\><sqrt|<big|int><rsub|\<bbb-R\><rsup|d>>(1+\|y\|<rsup|2>)<rsup|\<gamma\>>\|<wide|f|^>(y)\|<rsup|2>\<mathd\>y>,
  </equation*>

  a norm. Then <with|mode|math|H<rsup|2><rsub|\<gamma\>>> is the closure of
  <with|mode|math|C<rsup|\<infty\>><rsub|0>> in the norm
  <with|mode|math|<norm|\<cdot\>|y|>>.

  <with|mode|math|\<delta\>(x)>, <with|mode|math|<wide|\<delta\>|^>(x)=const>,
  <with|mode|math|\<delta\>\<in\>H<rsup|2><rsub|\<gamma\>>> for what
  <with|mode|math|\<gamma\>>? (<with|mode|math|\<gamma\>\<less\>-d/2?>)

  <with|mode|math|H<rsub|2><rsup|0>=L<rsub|2>>,
  <with|mode|math|H<rsub|2><rsup|\<gamma\><rsub|1>>\<subset\>H<rsub|2><rsup|\<gamma\><rsub|2>>>
  if <with|mode|math|\<gamma\><rsub|1>\<gtr\>\<gamma\><rsub|2>>.

  Sobolev embeddings: <with|mode|math|H<rsub|2><rsup|\<gamma\>+d/2>\<subset\>C<rsup|0,\<gamma\>>>
  if <with|mode|math|0\<less\>\<gamma\>\<less\>1>. Alternative (but
  equivalent) definition:

  <\equation*>
    H<rsub|2><rsup|n>={f:f,D f,\<ldots\>,D<rsup|n>f\<in\>L<rsup|2>}
  </equation*>

  with

  <\equation*>
    <norm|f|n|>\<sim\><norm|f|L<rsup|2>|>+<big|sum><rsub|k=1><rsup|n><norm|D<rsup|k>f|L<rsup|2>|>.
  </equation*>

  <with|mode|math|H<rsub|2><rsup|\<gamma\>>> is a Hilbert space with

  <\equation*>
    <ip|f|g|\<gamma\>|>=<big|int><rsub|\<bbb-R\><rsup|d>>(1+\|y\|<rsup|2>)<rsup|\<gamma\>><wide|f|^>(y)<wide|<wide|g|^>(y)|\<bar\>>\<mathd\>y.
  </equation*>

  <with|mode|math|H<rsub|2><rsup|\<gamma\>>> is dual to
  <with|mode|math|H<rsub|2><rsup|-\<gamma\>>> relative to
  <with|mode|math|L<rsup|2>>. (<with|mode|math|\<gamma\>\<gtr\>0>) Because if
  <with|mode|math|f\<in\>H<rsub|2><rsup|\<gamma\>>> and
  <with|mode|math|g\<in\>H<rsub|2><rsup|-\<gamma\>>>. Then

  <\equation*>
    <ip|f|g|0|>=<big|int><rsub|\<bbb-R\><rsup|d>>(1+\|y\|<rsup|2>)<rsup|\<gamma\>/2><wide|f|^>(y)<frac|<wide|<wide|g|^>(y)|\<bar\>>|(1+\|\<gamma\>\|<rsup|2>)<rsup|\<gamma\>/2>>\<mathd\>y\<leqslant\><norm|f|\<gamma\>|><norm|g|-\<gamma\>|>.
  </equation*>

  All this by S.L. Sobolev (1908-1989). Derived Sobolev spaces & generalized
  derivatives in the 1930s.

  <subsection|SPDEs in Sobolev Spaces>

  <subsubsection|Classical Theory>

  Let's consider the heat equation in <with|mode|math|(H<rsub|2><rsup|1>,L<rsub|2>,H<rsub|2><rsup|-1>)>,
  namely

  <\equation*>
    u<rsub|t>=u<rsub|x x>+f,<space|1em>u\|<rsub|t=0>=u<rsub|0>.
  </equation*>

  <\theorem>
    If <with|mode|math|u> is a classical solution and
    <with|mode|math|u(t,\<cdot\>)> and <with|mode|math|u<rsub|0>> are in
    <with|mode|math|C<rsup|\<infty\>><rsub|0>(\<bbb-R\>)>, then

    <\equation*>
      sup<rsub|t\<leqslant\>T><norm|u(t)|0|2>+<big|int><rsub|0><rsup|T><norm|u(t)|1|2>\<mathd\>t\<leqslant\>C(T)<left|(><norm|u<rsub|0>|0|2>+<big|int><rsub|0><rsup|T><norm|f(t)|-1|2>\<mathd\>t<right|)>.
    </equation*>

    (Note the slight abuse of notation with
    <with|mode|math|<norm|u(t)|\<gamma\>|>>.)
  </theorem>

  <\proof>
    \;

    <\eqnarray*>
      <tformat|<table|<row|<cell|<big|int>u<frac|\<partial\>u|\<partial\>t>\<mathd\>x>|<cell|=>|<cell|<big|int>u*u<rsub|x
      x>\<mathd\>x+<big|int>u*f\<mathd\>x<space|1em>\|<big|int>\<cdot\>u\<mathd\>x>>|<row|<cell|\<\|\|\>>|<cell|>|<cell|>>|<row|<cell|<frac|\<mathd\>v|\<mathd\>t>>|<cell|=>|<cell|<norm|u<rsub|x>|0|2>+<ip|u|f<rsub|0>||>\<pm\>2v(t)>>|<row|<cell|v(t)>|<cell|=>|<cell|v(0)-<big|int><rsub|0><rsup|t><left|(><norm|u(s)|0|2>+<norm|u<rsub|x>(s)|0|2><right|)>\<mathd\>s+<big|int><rsub|0><rsup|t><ip|u|f|0|>\<mathd\>s+2<big|int><rsub|0><rsup|t>v(s)\<mathd\>s>>|<row|<cell|v(t)+C<big|int><rsub|0><rsup|t><norm|u(s)|1|2>\<mathd\>s>|<cell|\<leqslant\>>|<cell|v(0)+<big|int><rsub|0><norm|u|1|><norm|f|-1|>\<mathd\>s+2<big|int>v(s)\<mathd\>s+<frac|C|2><big|int><rsub|0><rsup|t><norm|u|1|2>\<mathd\>s+C<rsub|1><big|int><rsub|0><rsup|t><norm|f|-1|2>\<mathd\>s>>|<row|<cell|v(t)+<frac|C|2><big|int><rsub|0><rsup|t><norm|u(s)|1|2>\<mathd\>s>|<cell|\<leqslant\>>|<cell|F+2<big|int><rsub|0><rsup|t>v(s)\<mathd\>s>>|<row|<cell|v(t)>|<cell|\<leqslant\>>|<cell|F+2<big|int><rsub|0><rsup|t>v(s)\<mathd\>s>>|<row|<cell|sup*v(t)>|<cell|\<leqslant\>>|<cell|F.>>>>
    </eqnarray*>

    where <with|mode|math|v(t)=<frac|1|2><norm|u(t)|0|2>> and all the
    constant-tweaking is done with the <with|mode|math|\<varepsilon\>>-inequality.
  </proof>

  <subsubsection|Stochastic Theory>

  <\equation*>
    \<mathd\>u=(a(t)u<rsub|x x>+f)\<mathd\>t+(\<sigma\>(t)u<rsub|x>+g)\<mathd\>W<rsub|t>,
  </equation*>

  where <with|mode|math|0\<less\>\<delta\>\<less\>a(t)-\<sigma\><rsup|2>(t)/2\<less\>C<rsup|\<ast\>>>.
  <with|mode|math|f,g> adapted to <with|mode|math|\<cal-F\><rsub|t><rsup|W>>,
  <with|mode|math|u,f,g\<in\>C<rsub|0><rsup|\<infty\>>>,
  <with|mode|math|u\|<rsub|t=0>=u<rsub|0>> independent of <with|mode|math|W>.
  Then

  <\equation*>
    E<left|[>sup<norm|u(t)|0|><right|]><rsup|2>+E<big|int><rsub|0><rsup|T><norm|u(t)|1|2>\<mathd\>t\<leqslant\>E<left|(><norm|u<rsub|0>|0|2>+<big|int><rsub|0><rsup|T><norm|f|-1|2>\<mathd\>t+<big|int><rsub|0><rsup|T><norm|g|0|2>\<mathd\>t<right|)>.
  </equation*>

  <em|Step 1:> WLOG, <with|mode|math|\<sigma\>=0> (check at home!). Use the
  substitution

  <\equation*>
    v(t,x)=u<left|(>t,x-<big|int><rsub|0><rsup|t>\<sigma\>(s)\<mathd\>W<rsub|s><right|)>.
  </equation*>

  <em|Step 2>: Ito formula for <with|mode|math|\|u(t,x)\|<rsup|2>>.

  <\equation*>
    u<rsup|2>=u<rsub|0><rsup|2>+2<wide*|<big|int><rsub|0><rsup|t>a*u<rsub|x
    x>*u\<mathd\>s|\<wide-underbrace\>><rsub|-<norm|u|1|2>>+<wide*|<big|int><rsub|0><rsup|t>f*u\<mathd\>s|\<wide-underbrace\>><rsub|\<varepsilon\><norm|u|1|2>+C<norm|f|-1|2>>+<big|int><rsub|0><rsup|t>g*u\<mathd\>W<rsub|s>+<big|int><rsub|0><rsup|t>g<rsup|2>\<mathd\>s.
  </equation*>

  <em|Step 3:> Take expectation, which kills the
  <with|mode|math|\<mathd\>W<rsub|s>> term, giving a bound on

  <\equation*>
    E<big|int><rsub|0><rsup|T><norm|u|1|2>\<mathd\>s<space|1em><with|mode|text|and><space|1em>E<norm|u(t)|0|2>.
  </equation*>

  <em|Step 4:> Take care of the sup, which is outside of the expectation, but
  needs to be inside.

  <\equation*>
    E<left|\|>sup<rsub|t><big|int><rsub|0><rsup|t<rsub|1>>g*u\<mathd\>W<right|\|>\<leqslant\>C*E<left|(><big|int><rsub|0><rsup|T><ip|g|u|0|2>\<mathd\>t<right|)><rsup|1/2>\<leqslant\>C*E<left|[>sup<rsub|t><big|int><rsub|0><rsup|T><norm|g|0|2>\<mathd\>t<right|]>\<leqslant\>\<varepsilon\>Esup<rsub|t><norm|u||2>+C(\<varepsilon\>)<big|int><rsub|0><rsup|t><norm|g|0|2>\<mathd\>s.
  </equation*>

  <section|Nonlinear Filtering (``Hidden Markov Models'')>

  State/signal <with|mode|math|X<rsub|t>>: Markov process/chain. Observation
  <with|mode|math|Y<rsub|t>=h(X<rsub|t>)+g<wide|V|\<dot\>>(t)>. State is not
  observed directly. The inf about <with|mode|math|X<rsub|t>> comes ``only''
  from <with|mode|math|Y<rsub|s>>, <with|mode|math|s\<leqslant\>t>. Find the
  best mean-squares estimate of <with|mode|math|f(X<rsub|t>)> given
  <with|mode|math|Y<rsub|s>>, <with|mode|math|s\<leqslant\>t>, where
  <with|mode|math|f> is a known function. <em|Claim:> This estimator is given
  by

  <\eqnarray*>
    <tformat|<table|<row|<cell|<wide|f|^><rsub|t>>|<cell|\<assign\>>|<cell|E<left|[>f(X<rsub|t>)\|\<cal-F\><rsub|t><rsup|Y><right|]>.>>>>
  </eqnarray*>

  <\proof>
    Let <with|mode|math|g<rsub|t>> be an <with|mode|math|\<cal-F\><rsub|t><rsup|Y>>-measurable
    square-integable function<with|mode|math|\<Leftrightarrow\>><with|mode|math|E[g<rsub|t><rsup|2>]\<less\>\<infty\>>,
    <with|mode|math|g<rsub|t>=g(Y<rsub|0><rsup|t>)>.

    <\eqnarray*>
      <tformat|<table|<row|<cell|E[f<rsub|t>-g<rsub|t>]<rsup|2>>|<cell|=>|<cell|E[f(X<rsub|t>)-<wide|f|^><rsub|t>+<wide|f|^><rsub|t>-g<rsub|t>]<rsup|2>>>|<row|<cell|>|<cell|=>|<cell|E[f(Y<rsub|t>)-<wide|f|^>(X<rsub|t>)]<rsup|2>+E[<wide|f|^><rsub|t>-g<rsub|t>]<rsup|2>>>|<row|<cell|>|<cell|\<geqslant\>>|<cell|E[f(X<rsub|t>)-<wide|f|^>(X<rsub|t>)]<rsup|2>+2E[(f(Y<rsub|t>)-<wide|f|^><rsub|t>)(<wide|f|^><rsub|t>-g<rsub|t>)]>>|<row|<cell|>|<cell|=>|<cell|E[E[(f(X<rsub|t>)-<wide|f|^><rsub|t>)(<wide|f|^><rsub|t>-g<rsub|t>)\|\<cal-F\><rsub|t><rsup|Y>]]=0.>>>>
    </eqnarray*>

    Geometric interpretation: conditional expectation, with respect ot the
    <with|mode|math|\<sigma\>>-algebra <with|mode|math|\<cal-G\>> is an
    orthogonal projection on a space of <with|mode|math|\<cal-G\>>-measurable
    functions.

    <\eqnarray*>
      <tformat|<table|<row|<cell|<wide|f|^><rsub|t>>|<cell|\<assign\>>|<cell|E[f(X<rsub|t>)\|\<cal-F\><rsub|t><rsup|Y>]>>|<row|<cell|>|<cell|=>|<cell|<big|int>f(x)P(X<rsub|t>\<in\>\<mathd\>x\|\<cal-F\><rsub|t><rsup|Y>).>>>>
    </eqnarray*>
  </proof>

  State:

  <\eqnarray*>
    <tformat|<table|<row|<cell|\<mathd\>X<rsub|t>>|<cell|=>|<cell|b(X<rsub|t>)\<mathd\>t+\<sigma\>(X(t))\<mathd\>W<rsub|t>>>|<row|<cell|\<mathd\>Y<rsub|t>>|<cell|=>|<cell|A(X(t))\<mathd\>t+g(Y<rsub|t>)\<mathd\>V<rsub|t>,>>>>
  </eqnarray*>

  We assume <with|mode|math|W<rsub|t>> and <with|mode|math|V<rsub|t>> are
  independent Wiener processes. <with|mode|math|X(0)=x<rsub|0>>,
  <with|mode|math|Y(0)=0>. Further <with|mode|math|f=f(x)>, with
  <with|mode|math|sup<rsub|t> E[f(X<rsub|t>)<rsup|2>]\<less\>\<infty\>>.

  <\eqnarray*>
    <tformat|<table|<row|<cell|<wide|f|^><rsub|t>>|<cell|=>|<cell|E[f(X<rsub|t>)\|\<cal-F\><rsub|t><rsup|Y>].>>>>
  </eqnarray*>

  <em|Zakai Equation of nonlinear filtering:>

  <\equation*>
    <wide|f|^><rsub|t>=<frac|<big|int>f(x)u(t,x)\<mathd\>x|<big|int>u(t,x)\<mathd\>x>,
  </equation*>

  where <with|mode|math|u(t,x)> is a solution of the <with|mode|math|SPDE>

  <\equation*>
    \<mathd\>u(t,x)=<left|[><frac|1|2>\<sigma\><rsup|2>(x)u(t,x)<rsub|x
    x>-(b(x)u(t,x))<rsub|x><right|]>\<mathd\>t+h(x)u(t,x)\<mathd\>Y<rsub|t>,
  </equation*>

  where <with|mode|math|h=g<rsup|-1>A>.

  <\eqnarray*>
    <tformat|<table|<row|<cell|<wide|P|~>(A)>|<cell|=>|<cell|<big|int><rsub|A>exp<left|{>-<big|int><rsub|0><rsup|T>h\<mathd\>s-<frac|1|2><big|int><rsub|0><rsup|T>h<rsup|2>\<mathd\>V<right|}>\<mathd\>P>>|<row|<cell|\<mathd\>Y<rsub|t>>|<cell|=>|<cell|\<mathd\>V<rsub|t>.>>>>
  </eqnarray*>

  If we add another term to the state process,

  <\equation*>
    \<mathd\>X<rsub|t>=b(X<rsub|t>)\<mathd\>t+\<sigma\>(X(t))\<mathd\>W<rsub|t>+f(X(t))\<mathd\>V<rsub|t>,
  </equation*>

  then we get

  <\equation*>
    \<mathd\>u(t,x)=<left|[><left|[><frac|1|2>\<sigma\><rsup|2>(x)+\<rho\><rsup|2><right|]>u(t,x)<rsub|x
    x>-(b(x)u(t,x))<rsub|x><right|]>\<mathd\>t-(\<rho\>u(t,x))<rsub|x>\<mathd\>Y<rsub|t>+h(x)u(t,x)\<mathd\>Y<rsub|t>
  </equation*>

  as the corresponding Zakai equation. (<with|color|red|not sure about this
  last equation>)

  <section|Solutions of PDEs and SPDEs>

  <subsection|Classical Solutions>

  Here, we assume that <with|mode|math|u> is twice continuously
  differentiable in <with|mode|math|x> and once in <with|mode|math|t>.

  <\equation>
    <label|eq:sol-heat><wide|u|\<dot\>>(t,x)=a(x)u<rsub|x
    x>,<space|1em>u(0,x)=u<rsub|0>(x).
  </equation>

  \;

  <subsection|Generalized Solutions>

  First, let us talk about generalized functions. Suppose we wanted to find a
  derivative of <with|mode|math|f(x)=sign(x)>. Classically,
  <with|mode|math|f<rprime|'>(0)> does not exist. Let <with|mode|math|g> be a
  differentiable function and <with|mode|math|\<varphi\>> very smooth with
  compact support. Then

  <\equation*>
    <big|int>f\<varphi\><rprime|'>(x)\<mathd\>x=-<big|int>f(x)\<varphi\>(x)\<mathd\>x.
  </equation*>

  If <with|mode|math|f> is not differentiable,

  <\equation*>
    <big|int>f<rprime|'>(x)\<varphi\>(x)\<mathd\>x=-<big|int>\<varphi\>(x)\<varphi\><rprime|'>(x)\<mathd\>x
  </equation*>

  for all <with|mode|math|\<varphi\>\<in\>C<rsub|0><rsup|\<infty\>>(\<bbb-R\><rsup|n>)>.

  Now reconsider the heat equation in a different form, namely

  <\equation>
    <label|eq:sol-rewritten-heat><wide|u|\<dot\>>(t,x)=(a(x)u<rsub|x>)<rsub|x>,<space|1em>u(0,x)=u<rsub|0>(x).
  </equation>

  A weak general solution of (<reference|eq:sol-rewritten-heat>) is a
  function <with|mode|math|u\<in\>H<rsub|2><rsup|1>(\<bbb-R\>)> such that for
  all <with|mode|math|t\<gtr\>0>

  <\equation*>
    <ip|u(t)|\<varphi\>||>=<ip|u<rsub|0>|\<varphi\>||>-<big|int><rsub|0><rsup|t><ip|u<rsub|x>|\<varphi\><rsub|x>||>\<mathd\>s
  </equation*>

  for every function <with|mode|math|\<varphi\>\<in\>C<rsub|0><rsup|\<infty\>>(\<bbb-R\>)>.

  Going back to (<reference|eq:sol-heat>), we find that a generalized
  solution is also a function from <with|mode|math|H<rsup|1><rsub|2>> so that

  <\equation*>
    <ip|u(t)|\<varphi\>||>=<ip|u<rsub|0>|\<varphi\>||>-<big|int><rsub|0><rsup|t><ip|u<rsub|x>|(a\<varphi\>)<rsub|x>||>\<mathd\>s
  </equation*>

  for all <with|mode|math|\<varphi\>\<in\>C<rsub|0><rsup|\<infty\>>(\<bbb-R\>)>.

  This definition is equivalent to saying that

  <\equation*>
    u(t)=u<rsub|0>+<big|int>a*u<rsub|x x>\<mathd\>s
  </equation*>

  as an equality in <with|mode|math|H<rsup|-1>>.

  <subsection|Mild Solutions>

  Let us now consider yet another different equation, namely

  <\equation>
    <label|eq:heat-nonlinear><wide|u|\<dot\>>(t,x)=u<rsub|x
    x>(t,x)+sin(u(t,x)),<space|1em>u(t,x)=u<rsub|0>(x).
  </equation>

  Direct differentiation shows

  <\equation*>
    u(t,x)=<big|int><rsub|\<bbb-R\>>k(t,x-y)u<rsub|0>(y)\<mathd\>y+<big|int><rsub|0><rsup|t><big|int><rsub|\<bbb-R\>>k(t-s,x-y)sin(u(s,y))\<mathd\>y\<mathd\>s,
  </equation*>

  where <with|mode|math|k> is the heat kernel

  <\equation*>
    k(t,x-y)=<frac|1|<sqrt|4\<pi\>t>>e<rsup|-<frac|\|x-y\|<rsup|2>|4t>>.
  </equation*>

  Write this now in SPDE form

  <\equation*>
    \<mathd\>u(t,x)=a*u<rsub|x x>+f(u(t,x)).
  </equation*>

  A <em|mild solution> is a solution <with|mode|math|u> that satisfies

  <\equation*>
    u(t,x)=<big|int><rsub|\<bbb-R\>>k(t,x-y)u<rsub|0>(y)\<mathd\>y+<big|int><rsub|0><rsup|t><big|int><rsub|\<bbb-R\>>k(t-s,x-y)f(u(s,y))\<mathd\>y\<mathd\>s.
  </equation*>

  <subsection|Generalization of the notion of a ``solution'' in SDE>

  OSDE

  <\equation*>
    \<mathd\>X<rsub|t>=b(X(t))\<mathd\>t+\<sigma\>(X(t))\<mathd\>W<rsub|t>,<space|1em>X<rsub|0>=x<rsub|0>.
  </equation*>

  Given <with|mode|math|b>, <with|mode|math|\<sigma\>>,
  <with|mode|math|x<rsub|0>>, <with|mode|math|(\<Omega\>,P)>,
  <with|mode|math|W>. If <with|mode|math|b> and <with|mode|math|\<sigma\>>
  are Lipschitz-continuous and

  <\equation*>
    \|b(x)\|\<leqslant\>K(1+\|x\|),<space|1em>\|\<sigma\>(x)\|\<leqslant\>K(1+\|x\|)<space|1em>\<Rightarrow\><space|1em>\<exists\>!u.
  </equation*>

  <em|Tanaka's Example> shows an OSDE that can't be solved in this way:

  <\equation*>
    \<mathd\>X<rsub|t>=sign(X<rsub|t>)\<mathd\>W<rsub|t>.
  </equation*>

  This equation has no solution for fixed <with|mode|math|(\<Omega\>,P)>,
  <with|mode|math|W>. One could find <with|mode|math|(<wide|\<Omega\>|~>,<wide|P|~>)>,
  <with|mode|math|<wide|W|~>> such that <with|mode|math|\<mathd\>X<rsub|t>=sign(X<rsub|t>)\<mathd\><wide|W|~><rsub|t>>.
  The mechanism for this is Girsanov's theorem, by which you can kill the
  drift and obtain a different equation.

  If you specify the measure space and the Wiener process, you are looking
  for a <em|probabilistically strong soltuion>. If you allow yourself the
  freedom of choosing these as part of your solution, your solution is
  <em|probabilistically weak>.

  <section|Existence and Uniqueness>

  <subsection|Scales of Sobolev Spaces>

  Simple Example: <with|mode|math|x\<in\>(0,b)>,
  <with|mode|math|\<Delta\>\<assign\>\<partial\><rsub|x><rsup|2>>,
  <with|mode|math|\<Lambda\>\<assign\>1-\<Delta\>>.
  <with|mode|math|H\<assign\>L<rsup|2>(0,b)>. For smooth functions
  <with|mode|math|f>, clearly

  <\equation*>
    <ip|\<Lambda\>f|f|H|>=<ip|(1-\<Delta\>)f|f|H|>=<big|int><rsub|0><rsup|b>f<rsup|2>(X)\<mathd\>x+<big|int><rsub|0><rsup|b>f<rsub|x><rsup|2>\<mathd\>x=:<norm|f|H<rsup|1><rsub|2>|2>.
  </equation*>

  Let us consider the basis

  <\equation*>
    <left|{>m<rsub|k>(x)=<sqrt|<frac|2|b>sin<frac|\<pi\>(k-1)x|b>><right|}>,
  </equation*>

  which is an ONS in <with|mode|math|H>. Observe

  <\equation*>
    \<Lambda\>m<rsub|k>=(1-\<Delta\>)m<rsub|k>=m<rsub|k>+<left|[><frac|\<pi\>(k-1)|b><right|]><rsup|2>m<rsub|k>=<left|(>1+<left|[><frac|\<pi\>(k-1)|b><right|]><rsup|2><right|)>m<rsub|k>.
  </equation*>

  Define

  <\equation*>
    \<lambda\><rsub|k>\<assign\>1+<left|[><frac|\<pi\>(k-1)|b><right|]><rsup|2>
  </equation*>

  as the eigenvalues of <with|mode|math|\<Lambda\>> w.r.t. the eigenbasis
  <with|mode|math|m<rsub|k>>. For <with|mode|math|s\<in\>(-\<infty\>,\<infty\>)>,
  we can construct an arbitrary power of the operator by defining its effect
  on the eigenbasis <with|mode|math|m<rsub|k><rsub|>> by
  <with|mode|math|\<Lambda\><rsup|s>m<rsub|k>\<assign\>\<lambda\><rsub|k><rsup|s>m<rsub|k>>.
  Further, we may observe

  <\equation*>
    <ip|\<Lambda\><rsup|s>f|f|H|>=<big|sum><rsub|k>\<lambda\><rsub|s><rsup|k>f<rsub|k>=<ip|\<Lambda\><rsup|s/2>f|\<Lambda\><rsup|s/2>f||>=<norm|\<Lambda\><rsup|s/2>|H|>,
  </equation*>

  where

  <\equation*>
    f<rsub|k>=<ip|f|m<rsub|k>|H|>
  </equation*>

  are the Fourier coefficients. Then the <em|Sobolev Space>

  <\equation*>
    H<rsub|2><rsup|s>(0,b)\<assign\><left|{>f\<in\>H:<norm|f|s|2>\<assign\><norm|\<Lambda\><rsup|s/2>f|H|2>\<less\>\<infty\><right|}>.
  </equation*>

  For <with|mode|math|s\<less\>0>, define

  <\equation*>
    H<rsub|2><rsup|s>(0,b)\<assign\>\<Lambda\><rsup|-s>H.
  </equation*>

  We may also define

  <\equation*>
    <norm|f|s|>\<assign\><sqrt|<big|sum><rsub|k\<geqslant\>1><ip|\<lambda\><rsub|k><rsup|s/2>f<rsub|k>|\<lambda\><rsub|k><rsup|s/2>f<rsub|k>||>>.<space|1em><with|color|red|<with|mode|text|It
    was><big|sum><rsub|k\<geqslant\>1><ip|\<lambda\><rsub|k><rsup|s/2>f<rsub|k>|\<lambda\><rsub|k><rsup|s>f<rsub|k>||><with|mode|text|on
    the board, but that seemed wrong.>>
  </equation*>

  The spaces <with|mode|math|{H<rsup|s><rsub|2>(0,b),s\<in\>\<bbb-R\>}> form
  the scale of spaces <with|mode|math|H<rsub|2><rsup|s<rsub|1>>\<subset\>H<rsub|2><rsup|s<rsub|2>>>
  if <with|mode|math|s<rsub|1>\<gtr\>s<rsub|2>>.

  Properties: Let <with|mode|math|s<rsub|1>\<gtr\>s<rsub|2>>. Then

  <\enumerate>
    <item><with|mode|math|H<rsup|s<rsub|1>>> is dense in
    <with|mode|math|H<rsup|s<rsub|2>>> in the norm
    <with|mode|math|<norm|\<cdot\>|s<rsub|2>|>>.

    <item><with|mode|math|H<rsup|s>> is a Hilbert space
    <with|mode|math|<ip|f|g|s|>=<ip|\<Lambda\><rsup|s/2>f|\<Lambda\><rsup|s/2>g|0|>>.

    <item>For <with|mode|math|s\<geqslant\>0>,
    <with|mode|math|v\<in\>H<rsup|-s>(0,b)>,
    <with|mode|math|u\<in\>H<rsup|s>(0,b)>, denote

    <\equation*>
      [u,v]\<assign\><ip|<wide*|\<Lambda\><rsup|s>v|\<wide-underbrace\>><rsub|\<in\>H>|<wide*|\<Lambda\><rsup|-s>u|\<wide-underbrace\>><rsub|\<in\>H>||>.
    </equation*>

    <\enumerate>
      <item>If <with|mode|math|v> also belongs to <with|mode|math|H>, then
      <with|mode|math|[u,v]=<ip|v|u|H|>>. Proof:
      <with|mode|math|\<Lambda\><rsup|s>> is self-adjoint in
      <with|mode|math|H>.
    </enumerate>
  </enumerate>

  <\remark>
    We will typically work with three elements of the Sobolev scale--the
    middle, e.g. <with|mode|math|L<rsup|2>>, then the space where the
    solution lives and finally the space that the solution gets mapped to by
    the operator.
  </remark>

  <em|Important mnemonic rule:>

  <\equation*>
    <wide*|<frac|\<partial\><rsup|n>|\<partial\>x<rsup|n>>|\<wide-underbrace\>><rsub|\<Lambda\><rsup|n/2>>:H<rsup|s>\<rightarrow\>H<rsup|s-n>.
  </equation*>

  <subsection|Normal triples/Rigged Hilbert space/Gelfand's triple>

  <\definition>
    The triple of Hilbert spaces <with|mode|math|(V,H,V<rprime|'>)> is called
    a normal triple if the following conditions hold:

    <\enumerate>
      <item><with|mode|math|V\<subset\>H\<subset\>V<rprime|'>>.

      <item>The imbeddings <with|mode|math|V\<rightarrow\>H\<rightarrow\>V<rprime|'>>
      are dense and continuous.

      <item><with|mode|math|><with|mode|math|V<rprime|'>> is the space dual
      to <with|mode|math|V> with respect to the scalar product in
      <with|mode|math|H>.
    </enumerate>

    Note that we always assume that <with|mode|math|H> is identified with its
    dual.
  </definition>

  <\example>
    Any triple <with|mode|math|H<rsup|s+\<gamma\>><rsub|2>,H<rsup|s>,H<rsup|s-\<gamma\>>>
    for <with|mode|math|\<gamma\>\<geqslant\>0> is a normal triple.
  </example>

  <subsection|Actual SPDEs>

  <\equation*>
    \<mathd\>u(t)=(A*u(t)=f(t))\<mathd\>t+<big|sum><rsub|k=1><rsup|\<infty\>>(M<rsub|k>u(t)+g<rsub|k>(t))\<mathd\>W<rsub|k><rsup|t>,<space|1em>u(0)=u<rsub|0>\<in\>H.
  </equation*>

  We will assume that <with|mode|math|A:V\<rightarrow\>V<rprime|'>> and
  <with|mode|math|M<rsub|k>:V\<rightarrow\>H>, and further
  <with|mode|math|f\<in\>L<rsup|2>(0,T;V<rprime|'>)> and
  <with|mode|math|g<rsub|k>\<in\>L<rsup|2>(0,T;H)>. We further assume
  <with|mode|math|f(t)> and <with|mode|math|g<rsub|k>(t)> are
  <with|mode|math|\<cal-F\><rsub|t><rsup|W>>-measurable, and
  <with|mode|math|V=H<rsub|2><rsup|1>(\<bbb-R\><rsup|d>)>,
  <with|mode|math|H=L<rsub|2>(\<bbb-R\><rsup|d>)>,
  <with|mode|math|V<rprime|'>=H<rsup|-1>(\<bbb-R\><rsup|d>)>.

  <\equation*>
    A*u=<big|sum><rsub|i,j>(a<rsup|i,j>(t,x)u<rsub|x<rsub|i>>)<rsub|x<rsub|j>>+<big|sum><rsub|i>b<rsup|i>(t,x)u<rsub|x<rsub|i>>+c.
  </equation*>

  <\equation*>
    M<rsub|k>u=<big|sum><rsub|i>\<sigma\><rsup|i,k>(t,x)u<rsub|x<rsub|i>>+h<rsup|k>(t,x)u.
  </equation*>

  We might also want to consider

  <\equation*>
    A u=<big|sum><rsub|\|\<alpha\>\|\<leqslant\>2n>a<rsub|\<alpha\>>\<partial\><rsup|\<alpha\>>u,<space|1em>M<rsub|k>u=<big|sum><rsub|\|\<alpha\>\|\<leqslant\>n>\<sigma\><rsub|\<alpha\>>\<partial\><rsup|\<alpha\>>u.
  </equation*>
</body>

<\initial>
  <\collection>
    <associate|page-type|letter>
  </collection>
</initial>

<\references>
  <\collection>
    <associate|auto-1|<tuple|<uninit>|1>>
    <associate|auto-10|<tuple|2.2.1|9>>
    <associate|auto-11|<tuple|2.2.2|11>>
    <associate|auto-12|<tuple|3|12>>
    <associate|auto-13|<tuple|4|14>>
    <associate|auto-14|<tuple|4.1|15>>
    <associate|auto-15|<tuple|4.2|15>>
    <associate|auto-16|<tuple|4.2.1|15>>
    <associate|auto-17|<tuple|4.2.2|16>>
    <associate|auto-18|<tuple|5|16>>
    <associate|auto-19|<tuple|6|17>>
    <associate|auto-2|<tuple|1|1>>
    <associate|auto-20|<tuple|6.1|17>>
    <associate|auto-21|<tuple|6.2|18>>
    <associate|auto-22|<tuple|6.3|18>>
    <associate|auto-23|<tuple|6.4|18>>
    <associate|auto-24|<tuple|7|?>>
    <associate|auto-25|<tuple|7.1|?>>
    <associate|auto-26|<tuple|7.2|?>>
    <associate|auto-27|<tuple|7.3|?>>
    <associate|auto-3|<tuple|1.1|2>>
    <associate|auto-4|<tuple|1.2|3>>
    <associate|auto-5|<tuple|1.3|4>>
    <associate|auto-6|<tuple|1.4|4>>
    <associate|auto-7|<tuple|2|6>>
    <associate|auto-8|<tuple|2.1|7>>
    <associate|auto-9|<tuple|2.2|9>>
    <associate|def:bm-def2|<tuple|1.18|5>>
    <associate|eq:ce-example-exp|<tuple|1.1|4>>
    <associate|eq:heat-nonlinear|<tuple|6.3|18>>
    <associate|eq:sol-heat|<tuple|6.1|17>>
    <associate|eq:sol-rewritten-heat|<tuple|6.2|18>>
  </collection>
</references>

<\auxiliary>
  <\collection>
    <\associate|toc>
      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|Table
      of contents> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-1><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|1<space|2spc>Basic
      Facts from Stochastic Processes> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-2><vspace|0.5fn>

      <with|par-left|<quote|1.5fn>|1.1<space|2spc>Lebesgue Integral
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-3>>

      <with|par-left|<quote|1.5fn>|1.2<space|2spc>Conditional Expectation
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-4>>

      <with|par-left|<quote|1.5fn>|1.3<space|2spc>Stochastic Processes
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-5>>

      <with|par-left|<quote|1.5fn>|1.4<space|2spc>Brownian Motion (Wiener
      Processes) <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-6>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|2<space|2spc>The
      Itô Integral and Formula> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-7><vspace|0.5fn>

      <with|par-left|<quote|1.5fn>|2.1<space|2spc>The Itô Construction
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-8>>

      <with|par-left|<quote|1.5fn>|2.2<space|2spc>Itô's Formula
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-9>>

      <with|par-left|<quote|3fn>|2.2.1<space|2spc>Deriving from the Chain
      Rule <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-10>>

      <with|par-left|<quote|3fn>|2.2.2<space|2spc>SODEs
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-11>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|3<space|2spc>Some
      SPDEs> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-12><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|4<space|2spc>PDE/Sobolev
      Recap> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-13><vspace|0.5fn>

      <with|par-left|<quote|1.5fn>|4.1<space|2spc>Sobolev Spaces
      <with|mode|<quote|math>|H<rsub|2><rsup|\<gamma\>>>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-14>>

      <with|par-left|<quote|1.5fn>|4.2<space|2spc>SPDEs in Sobolev Spaces
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-15>>

      <with|par-left|<quote|3fn>|4.2.1<space|2spc>Classical Theory
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-16>>

      <with|par-left|<quote|3fn>|4.2.2<space|2spc>Stochastic Theory
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-17>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|5<space|2spc>Nonlinear
      Filtering (``Hidden Markov Models'')>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-18><vspace|0.5fn>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|6<space|2spc>Solutions
      of PDEs and SPDEs> <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-19><vspace|0.5fn>

      <with|par-left|<quote|1.5fn>|6.1<space|2spc>Classical Solutions
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-20>>

      <with|par-left|<quote|1.5fn>|6.2<space|2spc>Generalized Solutions
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-21>>

      <with|par-left|<quote|1.5fn>|6.3<space|2spc>Mild Solutions
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-22>>

      <with|par-left|<quote|1.5fn>|6.4<space|2spc>Generalization of the
      notion of a ``solution'' in SDE <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-23>>
    </associate>
  </collection>
</auxiliary>